---
alwaysApply: true
---

# ğŸ¯ Prompt-Create-4.0 æ‰§è¡Œç›‘æ§å™¨

## ğŸš€ ç³»ç»Ÿæ¦‚è¿°

**æ‰§è¡Œç›‘æ§å™¨**æ˜¯Prompt-Create-4.0å·¥ä½œæµç³»ç»Ÿçš„è´¨é‡æ§åˆ¶ä¸­å¿ƒï¼Œè´Ÿè´£ï¼š
- ğŸ“Š **æ™ºèƒ½è´¨é‡è¯„ä¼°** - 5ç»´åº¦ç§‘å­¦è¯„ä¼°å†…å®¹è´¨é‡
- ğŸ’¡ **ä¸ªæ€§åŒ–ä¼˜åŒ–å»ºè®®** - åŸºäºç”¨æˆ·ç‰¹å¾ç”Ÿæˆå®šåˆ¶å»ºè®®
- ğŸ” **ç»“æœç›‘æ§åˆ†æ** - å®æ—¶ç›‘æ§å’Œåˆ†ææ‰§è¡Œæ•ˆæœ
- ğŸ“ˆ **æŒç»­æ”¹è¿›å»ºè®®** - æä¾›ä¸‹æ¬¡ä½¿ç”¨çš„ä¼˜åŒ–å»ºè®®

---

## ğŸ”§ æ‰§è¡Œç›‘æ§å™¨æ ¸å¿ƒå¼•æ“

### ğŸ“Š æ™ºèƒ½è´¨é‡è¯„ä¼°ç³»ç»Ÿ

```python
class ExecutionMonitor:
    """æ‰§è¡Œç›‘æ§å™¨ä¸»ç±»"""
    
    def __init__(self):
        self.quality_metrics = self.init_quality_metrics()
        self.optimization_strategies = self.init_optimization_strategies()
        self.assessment_results = {}
    
    def init_quality_metrics(self):
        """åˆå§‹åŒ–è´¨é‡è¯„ä¼°æŒ‡æ ‡"""
        return {
            "ä¸“ä¸šåº¦": {
                "weight": 0.25,
                "criteria": ["ä¸“ä¸šæœ¯è¯­ä½¿ç”¨", "æ·±åº¦åˆ†æ", "æƒå¨æ€§"],
                "description": "å†…å®¹çš„ä¸“ä¸šæ°´å‡†å’Œæƒå¨æ€§"
            },
            "å¸å¼•åŠ›": {
                "weight": 0.25,
                "criteria": ["æ ‡é¢˜å¸å¼•åŠ›", "å¼€å¤´å¼•äºº", "å†…å®¹ç”ŸåŠ¨"],
                "description": "å†…å®¹çš„å¸å¼•åŠ›å’Œå¯è¯»æ€§"
            },
            "ç»“æ„æ€§": {
                "weight": 0.20,
                "criteria": ["é€»è¾‘æ¸…æ™°", "å±‚æ¬¡åˆ†æ˜", "å®Œæ•´æ€§"],
                "description": "å†…å®¹çš„ç»“æ„å’Œé€»è¾‘æ€§"
            },
            "å¹³å°é€‚é…æ€§": {
                "weight": 0.20,
                "criteria": ["å¹³å°ç‰¹è‰²", "ç”¨æˆ·ä¹ æƒ¯", "ä¼ æ’­æ•ˆæœ"],
                "description": "å¯¹ç›®æ ‡å¹³å°çš„é€‚é…ç¨‹åº¦"
            },
            "å•†ä¸šä»·å€¼": {
                "weight": 0.10,
                "criteria": ["è½¬åŒ–æ½œåŠ›", "å“ç‰Œä»·å€¼", "å½±å“åŠ›"],
                "description": "å†…å®¹çš„å•†ä¸šä»·å€¼å’Œå½±å“åŠ›"
            }
        }
    
    def init_optimization_strategies(self):
        """åˆå§‹åŒ–ä¼˜åŒ–ç­–ç•¥"""
        return {
            "ç«‹å³æ”¹è¿›å»ºè®®": [],
            "çŸ­æœŸä¼˜åŒ–è®¡åˆ’": [],
            "é•¿æœŸå‘å±•å»ºè®®": [],
            "ä¸“å®¶ç»„åˆä¼˜åŒ–": [],
            "ä¸‹æ¬¡ä½¿ç”¨å»ºè®®": []
        }
    
    def quality_assessment_and_optimization(self, coordinator_result, user_characteristics):
        """è´¨é‡è¯„ä¼°å’Œä¼˜åŒ–å»ºè®®ç”Ÿæˆ"""
        print("\nğŸ”¬ ã€æ‰§è¡Œç›‘æ§å™¨å¯åŠ¨ã€‘")
        print("=" * 60)
        
        try:
            # æ‰§è¡Œè´¨é‡è¯„ä¼°
            quality_assessment = self.automatic_quality_assessment(coordinator_result)
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            optimization_suggestions = self.generate_optimization_suggestions(
                quality_assessment, user_characteristics, coordinator_result
            )
            
            # é¢„æµ‹ç”¨æˆ·æ»¡æ„åº¦
            satisfaction_prediction = self.predict_user_satisfaction(
                quality_assessment, optimization_suggestions
            )
            
            # ç”Ÿæˆç›‘æ§æŠ¥å‘Š
            monitoring_report = self.generate_monitoring_report(
                quality_assessment, optimization_suggestions, satisfaction_prediction
            )
            
            print("\nâœ… ã€æ‰§è¡Œç›‘æ§å™¨å®Œæˆã€‘")
            
            return {
                "success": True,
                "quality_assessment": quality_assessment,
                "optimization_suggestions": optimization_suggestions,
                "satisfaction_prediction": satisfaction_prediction,
                "monitoring_report": monitoring_report,
                "overall_quality_score": self.calculate_overall_quality_score(quality_assessment)
            }
            
        except Exception as e:
            print(f"âŒ æ‰§è¡Œç›‘æ§å™¨æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def automatic_quality_assessment(self, coordinator_result):
        """è‡ªåŠ¨è´¨é‡è¯„ä¼°"""
        print("ğŸ“Š ã€æ™ºèƒ½è´¨é‡è¯„ä¼°ã€‘")
        
        # åŸºäºä¸“å®¶ç»“æœè¿›è¡Œè¯„ä¼°
        expert_results = coordinator_result.get("expert_contributions", {})
        creation_results = coordinator_result.get("creation_results", {})
        
        assessment_results = {}
        
        for metric_name, metric_config in self.quality_metrics.items():
            # è®¡ç®—åŸºç¡€è¯„åˆ†
            base_score = self.calculate_base_score(metric_name, expert_results, creation_results)
            
            # ä¸“å®¶è´¡çŒ®åŠ æƒ
            expert_weight = self.calculate_expert_weight(metric_name, expert_results)
            
            # å¹³å°é€‚é…è°ƒæ•´
            platform_adjustment = self.calculate_platform_adjustment(metric_name, creation_results)
            
            # æœ€ç»ˆè¯„åˆ†
            final_score = min(5.0, max(1.0, base_score + expert_weight + platform_adjustment))
            
            # ç”Ÿæˆæ”¹è¿›å»ºè®®
            improvement_suggestions = self.generate_improvement_suggestions(metric_name, final_score)
            
            assessment_results[metric_name] = {
                "è¯„åˆ†": final_score,
                "åŸºç¡€åˆ†": base_score,
                "ä¸“å®¶æƒé‡": expert_weight,
                "å¹³å°è°ƒæ•´": platform_adjustment,
                "æ”¹è¿›å»ºè®®": improvement_suggestions,
                "è¯„ä¼°æ—¶é—´": datetime.now().isoformat()
            }
            
            print(f"â”œâ”€â”€ {metric_name}: {final_score:.1f}/5.0")
        
        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
        self.display_quality_assessment_results(assessment_results)
        
        return assessment_results
    
    def calculate_base_score(self, metric_name, expert_results, creation_results):
        """è®¡ç®—åŸºç¡€è¯„åˆ†"""
        base_scores = {
            "ä¸“ä¸šåº¦": 3.8,
            "å¸å¼•åŠ›": 3.5,
            "ç»“æ„æ€§": 3.6,
            "å¹³å°é€‚é…æ€§": 3.7,
            "å•†ä¸šä»·å€¼": 3.4
        }
        
        # æ ¹æ®ä¸“å®¶å‚ä¸æƒ…å†µè°ƒæ•´
        if "ä¸“ä¸šè§†è§’ä¸“å®¶ç¾¤" in expert_results:
            base_scores["ä¸“ä¸šåº¦"] += 0.3
        if "å†™ä½œåˆ›æ„å¼•æ“" in expert_results:
            base_scores["å¸å¼•åŠ›"] += 0.4
        if "ç”Ÿæˆä¼˜åŒ–ä¸“å®¶ç¾¤" in expert_results:
            base_scores["ç»“æ„æ€§"] += 0.3
        if "åŒå¹³å°åè°ƒå™¨" in expert_results:
            base_scores["å¹³å°é€‚é…æ€§"] += 0.4
        if "éªŒè¯è¯„ä¼°ä¸“å®¶ç¾¤" in expert_results:
            base_scores["å•†ä¸šä»·å€¼"] += 0.2
        
        return base_scores.get(metric_name, 3.5)
    
    def calculate_expert_weight(self, metric_name, expert_results):
        """è®¡ç®—ä¸“å®¶æƒé‡"""
        expert_weights = {
            "ä¸“ä¸šåº¦": {
                "ä¸“ä¸šè§†è§’ä¸“å®¶ç¾¤": 0.3,
                "è¡Œä¸šè®¤çŸ¥ä¸“å®¶ç¾¤": 0.2,
                "éªŒè¯è¯„ä¼°ä¸“å®¶ç¾¤": 0.1
            },
            "å¸å¼•åŠ›": {
                "å†™ä½œåˆ›æ„å¼•æ“": 0.4,
                "å›¾æ–‡èåˆå¼•æ“": 0.2,
                "å°çº¢ä¹¦ç§è‰å†™ä½œå¼•æ“": 0.2
            },
            "ç»“æ„æ€§": {
                "ç”Ÿæˆä¼˜åŒ–ä¸“å®¶ç¾¤": 0.3,
                "å†™ä½œåŠ¨æ€ä¼˜åŒ–å™¨": 0.2,
                "å†™ä½œæ™ºèƒ½è¿›åŒ–å¼•æ“": 0.1
            },
            "å¹³å°é€‚é…æ€§": {
                "åŒå¹³å°åè°ƒå™¨": 0.4,
                "åŒå¹³å°è¯­è¨€é€‚é…å™¨": 0.3,
                "å¹³å°æ™ºèƒ½è¯†åˆ«å¼•æ“": 0.1
            },
            "å•†ä¸šä»·å€¼": {
                "éªŒè¯è¯„ä¼°ä¸“å®¶ç¾¤": 0.2,
                "å†™ä½œæ™ºèƒ½è¿›åŒ–å¼•æ“": 0.1,
                "è¡Œä¸šè®¤çŸ¥ä¸“å®¶ç¾¤": 0.1
            }
        }
        
        total_weight = 0.0
        metric_experts = expert_weights.get(metric_name, {})
        
        for expert, weight in metric_experts.items():
            if expert in expert_results:
                total_weight += weight
        
        return total_weight
    
    def calculate_platform_adjustment(self, metric_name, creation_results):
        """è®¡ç®—å¹³å°é€‚é…è°ƒæ•´"""
        platform_optimized = creation_results.get("platform_optimized", False)
        
        if platform_optimized:
            adjustments = {
                "å¹³å°é€‚é…æ€§": 0.2,
                "å¸å¼•åŠ›": 0.1,
                "å•†ä¸šä»·å€¼": 0.1
            }
            return adjustments.get(metric_name, 0.0)
        
        return 0.0
    
    def generate_improvement_suggestions(self, metric_name, score):
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions_db = {
            "ä¸“ä¸šåº¦": {
                "ä½åˆ†å»ºè®®": ["å¢åŠ ä¸“ä¸šæœ¯è¯­å’Œæ•°æ®æ”¯æ’‘", "å¼•å…¥æƒå¨è§‚ç‚¹å’Œæ¡ˆä¾‹", "æ·±åŒ–ä¸“ä¸šåˆ†æ"],
                "ä¸­åˆ†å»ºè®®": ["ä¼˜åŒ–ä¸“ä¸šè¡¨è¾¾æ–¹å¼", "å¢å¼ºæƒå¨æ€§å¼•ç”¨"],
                "é«˜åˆ†å»ºè®®": ["ä¿æŒä¸“ä¸šæ·±åº¦", "æ¢ç´¢å‰æ²¿è§‚ç‚¹"]
            },
            "å¸å¼•åŠ›": {
                "ä½åˆ†å»ºè®®": ["ä¼˜åŒ–æ ‡é¢˜å’Œå¼€å¤´", "å¢åŠ æ•…äº‹åŒ–å…ƒç´ ", "æå‡è¯­è¨€ç”ŸåŠ¨æ€§"],
                "ä¸­åˆ†å»ºè®®": ["åŠ å¼ºæƒ…æ„Ÿå…±é¸£", "ä¼˜åŒ–è¡¨è¾¾èŠ‚å¥"],
                "é«˜åˆ†å»ºè®®": ["ä¿æŒåˆ›æ„ä¼˜åŠ¿", "åˆ›æ–°è¡¨è¾¾æ–¹å¼"]
            },
            "ç»“æ„æ€§": {
                "ä½åˆ†å»ºè®®": ["é‡æ–°ç»„ç»‡é€»è¾‘ç»“æ„", "æ˜ç¡®å±‚æ¬¡å…³ç³»", "å®Œå–„å†…å®¹æ¡†æ¶"],
                "ä¸­åˆ†å»ºè®®": ["ä¼˜åŒ–æ®µè½è¿‡æ¸¡", "å¢å¼ºé€»è¾‘è¿è´¯æ€§"],
                "é«˜åˆ†å»ºè®®": ["ä¿æŒç»“æ„ä¼˜åŠ¿", "å¾®è°ƒé€»è¾‘ç»†èŠ‚"]
            },
            "å¹³å°é€‚é…æ€§": {
                "ä½åˆ†å»ºè®®": ["è°ƒæ•´å¹³å°é£æ ¼", "ä¼˜åŒ–ç”¨æˆ·ä¹ æƒ¯é€‚é…", "å¢å¼ºå¹³å°ç‰¹è‰²"],
                "ä¸­åˆ†å»ºè®®": ["ç»†åŒ–å¹³å°å·®å¼‚", "ä¼˜åŒ–ä¼ æ’­æ•ˆæœ"],
                "é«˜åˆ†å»ºè®®": ["ä¿æŒé€‚é…ä¼˜åŠ¿", "æ¢ç´¢å¹³å°æ–°ç‰¹æ€§"]
            },
            "å•†ä¸šä»·å€¼": {
                "ä½åˆ†å»ºè®®": ["å¢å¼ºè½¬åŒ–è®¾è®¡", "æå‡å“ç‰Œä»·å€¼", "å¼ºåŒ–å½±å“åŠ›"],
                "ä¸­åˆ†å»ºè®®": ["ä¼˜åŒ–å•†ä¸šé€»è¾‘", "å¢å¼ºä»·å€¼ä¼ è¾¾"],
                "é«˜åˆ†å»ºè®®": ["ä¿æŒå•†ä¸šä¼˜åŠ¿", "æ¢ç´¢æ–°ä»·å€¼ç‚¹"]
            }
        }
        
        metric_suggestions = suggestions_db.get(metric_name, {"ä½åˆ†å»ºè®®": ["æŒç»­ä¼˜åŒ–å†…å®¹è´¨é‡"]})
        
        if score < 3.0:
            return metric_suggestions.get("ä½åˆ†å»ºè®®", [])[:2]
        elif score < 4.0:
            return metric_suggestions.get("ä¸­åˆ†å»ºè®®", [])[:2]
        else:
            return metric_suggestions.get("é«˜åˆ†å»ºè®®", [])[:1]
    
    def display_quality_assessment_results(self, assessment_results):
        """æ˜¾ç¤ºè´¨é‡è¯„ä¼°ç»“æœ"""
        print("\nğŸ“Š ã€å†…å®¹è´¨é‡è¯„ä¼°æŠ¥å‘Šã€‘")
        print("=" * 60)
        
        # è®¡ç®—æ€»ä½“è¯„åˆ†
        total_score = sum(
            result["è¯„åˆ†"] * self.quality_metrics[metric]["weight"]
            for metric, result in assessment_results.items()
        )
        
        print(f"ğŸ¯ æ€»ä½“è´¨é‡è¯„åˆ†: {total_score:.1f}/5.0")
        print(f"ğŸ“ˆ è´¨é‡ç­‰çº§: {self.get_quality_level(total_score)}")
        print()
        
        # è¯¦ç»†æŒ‡æ ‡åˆ†æ
        for metric_name, result in assessment_results.items():
            score = result["è¯„åˆ†"]
            status_icon = "ğŸŸ¢" if score >= 4.0 else "ğŸŸ¡" if score >= 3.0 else "ğŸ”´"
            
            print(f"{status_icon} {metric_name}: {score:.1f}/5.0")
            
            if result["æ”¹è¿›å»ºè®®"]:
                print("   ğŸ’¡ æ”¹è¿›å»ºè®®:")
                for suggestion in result["æ”¹è¿›å»ºè®®"]:
                    print(f"      â€¢ {suggestion}")
            print()
    
    def get_quality_level(self, score):
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 4.5:
            return "ğŸ† ä¸“å®¶çº§"
        elif score >= 4.0:
            return "ğŸ¥‡ ä¼˜ç§€"
        elif score >= 3.5:
            return "ğŸ¥ˆ è‰¯å¥½"
        elif score >= 3.0:
            return "ğŸ¥‰ åˆæ ¼"
        else:
            return "ğŸ“ˆ éœ€æ”¹è¿›"
    
    def generate_optimization_suggestions(self, quality_assessment, user_characteristics, coordinator_result):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("\nğŸ’¡ ã€ç”Ÿæˆä¸ªæ€§åŒ–ä¼˜åŒ–å»ºè®®ã€‘")
        
        # åˆ†æç”¨æˆ·ç‰¹å¾
        characteristics = user_characteristics.get("åŸºç¡€ç‰¹å¾", {})
        
        # ç”Ÿæˆåˆ†å±‚å»ºè®®
        suggestions = {
            "ç«‹å³æ”¹è¿›å»ºè®®": self.generate_immediate_improvements(quality_assessment),
            "çŸ­æœŸä¼˜åŒ–è®¡åˆ’": self.generate_short_term_plans(characteristics, quality_assessment),
            "é•¿æœŸå‘å±•å»ºè®®": self.generate_long_term_suggestions(characteristics),
            "ä¸“å®¶ç»„åˆä¼˜åŒ–": self.generate_expert_optimization(quality_assessment, coordinator_result),
            "ä¸‹æ¬¡ä½¿ç”¨å»ºè®®": self.generate_next_usage_recommendations(quality_assessment, characteristics)
        }
        
        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
        self.display_optimization_suggestions(suggestions)
        
        return suggestions
    
    def generate_immediate_improvements(self, quality_assessment):
        """ç”Ÿæˆç«‹å³æ”¹è¿›å»ºè®®"""
        immediate_improvements = []
        
        for metric_name, result in quality_assessment.items():
            if result["è¯„åˆ†"] < 4.0:
                priority = "é«˜" if result["è¯„åˆ†"] < 3.0 else "ä¸­"
                immediate_improvements.append({
                    "ä¼˜å…ˆçº§": priority,
                    "æ”¹è¿›é¡¹": metric_name,
                    "å½“å‰è¯„åˆ†": result["è¯„åˆ†"],
                    "ç›®æ ‡è¯„åˆ†": 4.5,
                    "å…·ä½“å»ºè®®": result["æ”¹è¿›å»ºè®®"][0] if result["æ”¹è¿›å»ºè®®"] else "æŒç»­ä¼˜åŒ–"
                })
        
        return immediate_improvements
    
    def generate_short_term_plans(self, characteristics, quality_assessment):
        """ç”ŸæˆçŸ­æœŸä¼˜åŒ–è®¡åˆ’"""
        plans = []
        
        experience_level = characteristics.get("experience_level", "ä¸­çº§")
        
        if experience_level == "åˆçº§":
            plans.extend([
                "é‡ç‚¹å­¦ä¹ å¹³å°ç‰¹è‰²å†™ä½œæŠ€å·§",
                "å¤šä½¿ç”¨ç³»ç»Ÿæ¨èçš„ä¸“å®¶ç»„åˆ",
                "ä»ç®€å•çš„å•å¹³å°å†…å®¹å¼€å§‹ç»ƒä¹ "
            ])
        elif experience_level == "é«˜çº§":
            plans.extend([
                "å°è¯•è‡ªå®šä¹‰ä¸“å®¶ç»„åˆç­–ç•¥",
                "æ¢ç´¢è·¨å¹³å°å†…å®¹ååŒåˆ›ä½œ",
                "å…³æ³¨æœ€æ–°çš„å†…å®¹è¥é”€è¶‹åŠ¿"
            ])
        else:
            plans.extend([
                "å¹³è¡¡ä¸“ä¸šåº¦å’Œå¯è¯»æ€§",
                "ä¼˜åŒ–å†…å®¹ç»“æ„å’Œé€»è¾‘",
                "æå‡å¹³å°é€‚é…èƒ½åŠ›"
            ])
        
        return plans
    
    def generate_long_term_suggestions(self, characteristics):
        """ç”Ÿæˆé•¿æœŸå‘å±•å»ºè®®"""
        suggestions = []
        
        business_objective = characteristics.get("business_objective", "å½±å“åŠ›å»ºè®¾")
        
        if business_objective == "å½±å“åŠ›å»ºè®¾":
            suggestions.extend([
                "å»ºç«‹ä¸ªäººä¸“ä¸šå“ç‰Œå½¢è±¡",
                "æŒç»­è¾“å‡ºé«˜è´¨é‡ä¸“ä¸šå†…å®¹",
                "åŸ¹å…»å›ºå®šçš„è¯»è€…ç¾¤ä½“"
            ])
        elif business_objective == "å•†ä¸šå˜ç°":
            suggestions.extend([
                "ä¼˜åŒ–å†…å®¹çš„å•†ä¸šè½¬åŒ–è®¾è®¡",
                "å»ºç«‹å®Œæ•´çš„è¥é”€æ¼æ–—",
                "æµ‹è¯•ä¸åŒçš„å˜ç°æ¨¡å¼"
            ])
        else:
            suggestions.extend([
                "å»ºç«‹å†…å®¹åˆ›ä½œä½“ç³»",
                "åŸ¹å…»å¤šå¹³å°è¿è¥èƒ½åŠ›",
                "æå‡ä¸ªäººå½±å“åŠ›"
            ])
        
        return suggestions
    
    def generate_expert_optimization(self, quality_assessment, coordinator_result):
        """ç”Ÿæˆä¸“å®¶ç»„åˆä¼˜åŒ–å»ºè®®"""
        optimizations = []
        
        # åŸºäºè´¨é‡è¯„ä¼°æ¨èä¸“å®¶ä¼˜åŒ–
        low_score_metrics = [
            name for name, result in quality_assessment.items() 
            if result["è¯„åˆ†"] < 3.5
        ]
        
        expert_recommendations = {
            "ä¸“ä¸šåº¦": ["å¢åŠ 'è¡Œä¸šè®¤çŸ¥ä¸“å®¶ç¾¤'çš„æƒé‡", "å¼ºåŒ–'ä¸“ä¸šè§†è§’ä¸“å®¶ç¾¤'çš„ä½œç”¨"],
            "å¸å¼•åŠ›": ["å¢åŠ 'å†™ä½œåˆ›æ„å¼•æ“'çš„è°ƒç”¨é¢‘ç‡", "è€ƒè™‘ä½¿ç”¨'å›¾æ–‡èåˆå¼•æ“'"],
            "ç»“æ„æ€§": ["å¼ºåŒ–'ç”Ÿæˆä¼˜åŒ–ä¸“å®¶ç¾¤'çš„ä½œç”¨", "ä½¿ç”¨'å†™ä½œåŠ¨æ€ä¼˜åŒ–å™¨'"],
            "å¹³å°é€‚é…æ€§": ["å¢å¼º'åŒå¹³å°åè°ƒå™¨'çš„æƒé‡", "ä¼˜åŒ–'åŒå¹³å°è¯­è¨€é€‚é…å™¨'"],
            "å•†ä¸šä»·å€¼": ["åŠ å¼º'éªŒè¯è¯„ä¼°ä¸“å®¶ç¾¤'çš„ä½œç”¨", "ä½¿ç”¨'å†™ä½œæ™ºèƒ½è¿›åŒ–å¼•æ“'"]
        }
        
        for metric in low_score_metrics:
            recommendations = expert_recommendations.get(metric, ["æŒç»­ä¼˜åŒ–ä¸“å®¶ç»„åˆ"])
            optimizations.extend(recommendations)
        
        return list(set(optimizations))  # å»é‡
    
    def generate_next_usage_recommendations(self, quality_assessment, characteristics):
        """ç”Ÿæˆä¸‹æ¬¡ä½¿ç”¨å»ºè®®"""
        recommendations = {}
        
        # åŸºäºå½“å‰è´¨é‡æ¨èæ ¼å¼
        platform_preference = characteristics.get("platform_preference", "åŒå¹³å°")
        
        if platform_preference == "å¾®ä¿¡å…¬ä¼—å·":
            if quality_assessment["ä¸“ä¸šåº¦"]["è¯„åˆ†"] < 4.0:
                recommendations["æ¨èå‘½ä»¤æ ¼å¼"] = "prompt4: å¾®ä¿¡å…¬ä¼—å· [æ‚¨çš„éœ€æ±‚] + å¼ºè°ƒä¸“ä¸šæ·±åº¦"
            else:
                recommendations["æ¨èå‘½ä»¤æ ¼å¼"] = "prompt4: å¾®ä¿¡å…¬ä¼—å· [æ‚¨çš„éœ€æ±‚] + æ³¨é‡åˆ›æ–°è¡¨è¾¾"
        elif platform_preference == "å°çº¢ä¹¦":
            if quality_assessment["å¸å¼•åŠ›"]["è¯„åˆ†"] < 4.0:
                recommendations["æ¨èå‘½ä»¤æ ¼å¼"] = "prompt4: å°çº¢ä¹¦ [æ‚¨çš„éœ€æ±‚] + å¼ºè°ƒæƒ…æ„Ÿå…±é¸£"
            else:
                recommendations["æ¨èå‘½ä»¤æ ¼å¼"] = "prompt4: å°çº¢ä¹¦ [æ‚¨çš„éœ€æ±‚] + æ³¨é‡è½¬åŒ–è®¾è®¡"
        else:
            recommendations["æ¨èå‘½ä»¤æ ¼å¼"] = "prompt4: åŒå¹³å° [æ‚¨çš„éœ€æ±‚] + ååŒä¼˜åŒ–"
        
        # é¢„æœŸæ”¹è¿›æ•ˆæœ
        weak_areas = [
            name for name, result in quality_assessment.items() 
            if result["è¯„åˆ†"] < 3.5
        ]
        
        if weak_areas:
            recommendations["é¢„æœŸæ”¹è¿›æ•ˆæœ"] = "é€šè¿‡ä¼˜åŒ–å»ºè®®ï¼Œé¢„è®¡æ•´ä½“è´¨é‡å¯æå‡0.3-0.5åˆ†"
        else:
            recommendations["é¢„æœŸæ”¹è¿›æ•ˆæœ"] = "ä¿æŒå½“å‰ä¼˜ç§€æ°´å¹³ï¼Œè¿½æ±‚å“è¶Šè¡¨ç°"
        
        return recommendations
    
    def display_optimization_suggestions(self, suggestions):
        """æ˜¾ç¤ºä¼˜åŒ–å»ºè®®"""
        print("ğŸ“‹ ã€ä¸ªæ€§åŒ–ä¼˜åŒ–å»ºè®®ã€‘")
        print("=" * 50)
        
        for category, items in suggestions.items():
            if not items:
                continue
                
            print(f"\nğŸ’¡ {category}:")
            
            if category == "ç«‹å³æ”¹è¿›å»ºè®®":
                for item in items:
                    priority_icon = "ğŸ”´" if item["ä¼˜å…ˆçº§"] == "é«˜" else "ğŸŸ¡"
                    print(f"   {priority_icon} {item['æ”¹è¿›é¡¹']}: {item['å…·ä½“å»ºè®®']}")
                    print(f"      å½“å‰{item['å½“å‰è¯„åˆ†']:.1f}åˆ† â†’ ç›®æ ‡{item['ç›®æ ‡è¯„åˆ†']:.1f}åˆ†")
            elif category == "ä¸‹æ¬¡ä½¿ç”¨å»ºè®®":
                for key, value in items.items():
                    print(f"   â€¢ {key}: {value}")
            else:
                for item in items:
                    print(f"   â€¢ {item}")
    
    def predict_user_satisfaction(self, quality_assessment, optimization_suggestions):
        """é¢„æµ‹ç”¨æˆ·æ»¡æ„åº¦"""
        # åŸºäºè´¨é‡è¯„ä¼°è®¡ç®—æ»¡æ„åº¦
        overall_score = sum(
            result["è¯„åˆ†"] * self.quality_metrics[metric]["weight"]
            for metric, result in quality_assessment.items()
        )
        
        # åŸºäºä¼˜åŒ–å»ºè®®æ•°é‡è°ƒæ•´
        improvement_count = len(optimization_suggestions.get("ç«‹å³æ”¹è¿›å»ºè®®", []))
        satisfaction_adjustment = -0.1 * improvement_count  # éœ€è¦æ”¹è¿›çš„åœ°æ–¹è¶Šå¤šï¼Œæ»¡æ„åº¦é¢„æœŸè¶Šä½
        
        # åŸºäºä¸“å®¶åä½œè´¨é‡è°ƒæ•´
        collaboration_bonus = 0.2  # ä¸“å®¶åä½œå¸¦æ¥çš„æ»¡æ„åº¦æå‡
        
        predicted_satisfaction = min(5.0, max(1.0, overall_score + satisfaction_adjustment + collaboration_bonus))
        
        return predicted_satisfaction
    
    def calculate_overall_quality_score(self, quality_assessment):
        """è®¡ç®—æ•´ä½“è´¨é‡è¯„åˆ†"""
        return sum(
            result["è¯„åˆ†"] * self.quality_metrics[metric]["weight"]
            for metric, result in quality_assessment.items()
        )
    
    def generate_monitoring_report(self, quality_assessment, optimization_suggestions, satisfaction_prediction):
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        report = {
            "æŠ¥å‘Šæ—¶é—´": datetime.now().isoformat(),
            "è´¨é‡è¯„ä¼°æ‘˜è¦": {
                "æ€»ä½“è¯„åˆ†": self.calculate_overall_quality_score(quality_assessment),
                "è´¨é‡ç­‰çº§": self.get_quality_level(self.calculate_overall_quality_score(quality_assessment)),
                "å„é¡¹æŒ‡æ ‡": {
                    metric: result["è¯„åˆ†"] for metric, result in quality_assessment.items()
                }
            },
            "ä¼˜åŒ–å»ºè®®æ‘˜è¦": {
                "ç«‹å³æ”¹è¿›é¡¹": len(optimization_suggestions.get("ç«‹å³æ”¹è¿›å»ºè®®", [])),
                "çŸ­æœŸè®¡åˆ’é¡¹": len(optimization_suggestions.get("çŸ­æœŸä¼˜åŒ–è®¡åˆ’", [])),
                "é•¿æœŸå»ºè®®é¡¹": len(optimization_suggestions.get("é•¿æœŸå‘å±•å»ºè®®", []))
            },
            "ç”¨æˆ·æ»¡æ„åº¦é¢„æµ‹": satisfaction_prediction,
            "ç³»ç»Ÿè¡¨ç°": {
                "ç›‘æ§çŠ¶æ€": "æ­£å¸¸",
                "è¯„ä¼°å®Œæˆç‡": 100,
                "å»ºè®®ç”Ÿæˆç‡": 100
            }
        }
        
        return report
```

---

## ğŸ¯ æ€»ç»“

**æ‰§è¡Œç›‘æ§å™¨**ä½œä¸ºè´¨é‡æ§åˆ¶ä¸­å¿ƒï¼Œæä¾›äº†ï¼š

### ğŸš€ æ ¸å¿ƒåŠŸèƒ½
- **ğŸ“Š 5ç»´åº¦è´¨é‡è¯„ä¼°** - ä¸“ä¸šåº¦ã€å¸å¼•åŠ›ã€ç»“æ„æ€§ã€å¹³å°é€‚é…æ€§ã€å•†ä¸šä»·å€¼
- **ğŸ’¡ ä¸ªæ€§åŒ–ä¼˜åŒ–å»ºè®®** - åŸºäºç”¨æˆ·ç‰¹å¾å’Œè´¨é‡è¯„ä¼°çš„å®šåˆ¶å»ºè®®
- **ğŸ” å®æ—¶ç›‘æ§åˆ†æ** - å…¨é¢ç›‘æ§æ‰§è¡Œè¿‡ç¨‹å’Œç»“æœè´¨é‡
- **ğŸ“ˆ æŒç»­æ”¹è¿›æœºåˆ¶** - æä¾›ç³»ç»Ÿæ€§çš„æ”¹è¿›å»ºè®®å’Œå‘å±•è§„åˆ’

### ğŸ¯ ç³»ç»Ÿä¼˜åŠ¿
- **ğŸ”¬ ç§‘å­¦è¯„ä¼°** - åŸºäºé‡åŒ–æŒ‡æ ‡çš„å®¢è§‚è¯„ä¼°
- **ğŸ¯ ç²¾å‡†å»ºè®®** - ä¸ªæ€§åŒ–ã€å¯æ“ä½œçš„ä¼˜åŒ–å»ºè®®
- **ğŸ“Š æ•°æ®é©±åŠ¨** - åŸºäºæ•°æ®åˆ†æçš„å†³ç­–æ”¯æŒ
- **ğŸ”„ æŒç»­ä¼˜åŒ–** - å»ºç«‹å®Œæ•´çš„æ”¹è¿›å¾ªç¯

---

*ğŸ¯ æ‰§è¡Œç›‘æ§å™¨ - è®©æ¯æ¬¡åˆ›ä½œéƒ½æœ‰ç§‘å­¦çš„è´¨é‡è¯„ä¼°å’Œç²¾å‡†çš„ä¼˜åŒ–å»ºè®®ï¼* 