# ğŸ”„ åŒºå—é“¾æ•°æ®åŒæ­¥æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

åŒºå—é“¾æ•°æ®åŒæ­¥æ˜¯ Web3 åº”ç”¨çš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€ï¼Œæœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨ Go è¯­è¨€æ„å»ºé«˜æ€§èƒ½ã€å¯é çš„åŒºå—é“¾æ•°æ®åŒæ­¥ç³»ç»Ÿï¼ŒåŒ…æ‹¬å®æ—¶æ•°æ®åŒæ­¥ã€å†å²æ•°æ®å›å¡«ã€æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ç­‰å…³é”®æŠ€æœ¯ã€‚

## ğŸ—ï¸ åŒæ­¥æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å›¾

```mermaid
graph TB
    A[åŒºå—é“¾ç½‘ç»œ] --> B[RPCèŠ‚ç‚¹]
    B --> C[æ•°æ®è·å–å±‚]
    C --> D[æ•°æ®è§£æå™¨]
    D --> E[æ•°æ®éªŒè¯å™¨]
    E --> F[æ•°æ®å¤„ç†é˜Ÿåˆ—]
    F --> G[æ•°æ®åº“å­˜å‚¨å±‚]
    G --> H[ç´¢å¼•æ„å»ºå™¨]
    H --> I[APIæœåŠ¡å±‚]
    
    J[ç›‘æ§ç³»ç»Ÿ] --> C
    J --> F
    J --> G
    
    K[ç¼“å­˜å±‚] --> G
    K --> I
```

### æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | èŒè´£ | æŠ€æœ¯é€‰å‹ |
|------|------|----------|
| æ•°æ®è·å–å±‚ | ä»RPCèŠ‚ç‚¹è·å–åŸå§‹åŒºå—æ•°æ® | go-ethereum, WebSocket |
| æ•°æ®è§£æå™¨ | è§£æåŒºå—ã€äº¤æ˜“ã€äº‹ä»¶æ•°æ® | ABIè§£æ, äº‹ä»¶è¿‡æ»¤ |
| æ•°æ®éªŒè¯å™¨ | éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§ | å“ˆå¸ŒéªŒè¯, é“¾å¼éªŒè¯ |
| å¤„ç†é˜Ÿåˆ— | å¼‚æ­¥å¤„ç†å’Œæ‰¹é‡æ“ä½œ | Channel, Worker Pool |
| å­˜å‚¨å±‚ | æŒä¹…åŒ–å­˜å‚¨å’Œç´¢å¼• | MySQL, åˆ†åŒºè¡¨ |

## ğŸ”§ åŒæ­¥å™¨å®ç°

### 1. åŸºç¡€åŒæ­¥å™¨

```go
package sync

import (
    "context"
    "fmt"
    "math/big"
    "sync"
    "time"
    
    "github.com/ethereum/go-ethereum/core/types"
    "go.uber.org/zap"
)

// åŒæ­¥å™¨çŠ¶æ€
type SyncStatus int

const (
    StatusStopped SyncStatus = iota
    StatusStarting
    StatusSyncing
    StatusCaughtUp
    StatusError
)

// åŒæ­¥å™¨æ¥å£
type Synchronizer interface {
    Start(ctx context.Context) error
    Stop() error
    GetStatus() SyncStatus
    GetProgress() *SyncProgress
}

// åŒæ­¥è¿›åº¦
type SyncProgress struct {
    CurrentBlock   uint64    `json:"current_block"`
    LatestBlock    uint64    `json:"latest_block"`
    SyncedBlocks   uint64    `json:"synced_blocks"`
    StartTime      time.Time `json:"start_time"`
    BlocksPerSec   float64   `json:"blocks_per_sec"`
    EstimatedTime  string    `json:"estimated_time"`
}

// ä¸»åŒæ­¥å™¨
type MainSynchronizer struct {
    client       EthereumClient
    storage      StorageInterface
    config       *SyncConfig
    logger       *zap.Logger
    
    // çŠ¶æ€ç®¡ç†
    mu           sync.RWMutex
    status       SyncStatus
    progress     *SyncProgress
    
    // æ§åˆ¶é€šé“
    stopCh       chan struct{}
    errorCh      chan error
    
    // å·¥ä½œé˜Ÿåˆ—
    blockQueue   chan uint64
    resultQueue  chan *BlockResult
    
    // Worker æ± 
    workers      []*SyncWorker
    workerWg     sync.WaitGroup
}

type SyncConfig struct {
    StartBlock     uint64        `yaml:"start_block"`
    EndBlock       uint64        `yaml:"end_block"`       // 0 è¡¨ç¤ºæŒç»­åŒæ­¥
    BatchSize      int           `yaml:"batch_size"`
    WorkerCount    int           `yaml:"worker_count"`
    QueueSize      int           `yaml:"queue_size"`
    SyncInterval   time.Duration `yaml:"sync_interval"`
    RetryLimit     int           `yaml:"retry_limit"`
    RetryDelay     time.Duration `yaml:"retry_delay"`
    ProgressReport time.Duration `yaml:"progress_report"`
}

func NewMainSynchronizer(
    client EthereumClient,
    storage StorageInterface,
    config *SyncConfig,
    logger *zap.Logger,
) *MainSynchronizer {
    return &MainSynchronizer{
        client:      client,
        storage:     storage,
        config:      config,
        logger:      logger,
        status:      StatusStopped,
        stopCh:      make(chan struct{}),
        errorCh:     make(chan error, 10),
        blockQueue:  make(chan uint64, config.QueueSize),
        resultQueue: make(chan *BlockResult, config.QueueSize),
        progress: &SyncProgress{
            StartTime: time.Now(),
        },
    }
}

func (s *MainSynchronizer) Start(ctx context.Context) error {
    s.mu.Lock()
    if s.status != StatusStopped {
        s.mu.Unlock()
        return fmt.Errorf("åŒæ­¥å™¨å·²åœ¨è¿è¡Œï¼Œå½“å‰çŠ¶æ€: %v", s.status)
    }
    s.status = StatusStarting
    s.mu.Unlock()
    
    s.logger.Info("å¯åŠ¨åŒºå—é“¾æ•°æ®åŒæ­¥å™¨", 
        zap.Uint64("start_block", s.config.StartBlock),
        zap.Int("worker_count", s.config.WorkerCount),
    )
    
    // è·å–å½“å‰åŒæ­¥è¿›åº¦
    if err := s.loadProgress(ctx); err != nil {
        s.setStatus(StatusError)
        return fmt.Errorf("åŠ è½½åŒæ­¥è¿›åº¦å¤±è´¥: %w", err)
    }
    
    // å¯åŠ¨å·¥ä½œåç¨‹
    s.startWorkers(ctx)
    
    // å¯åŠ¨ç»“æœå¤„ç†åç¨‹
    go s.resultProcessor(ctx)
    
    // å¯åŠ¨è¿›åº¦æŠ¥å‘Šåç¨‹
    go s.progressReporter(ctx)
    
    // å¯åŠ¨ä¸»åŒæ­¥å¾ªç¯
    go s.syncLoop(ctx)
    
    s.setStatus(StatusSyncing)
    return nil
}

func (s *MainSynchronizer) Stop() error {
    s.mu.Lock()
    if s.status == StatusStopped {
        s.mu.Unlock()
        return nil
    }
    s.mu.Unlock()
    
    s.logger.Info("åœæ­¢åŒºå—é“¾æ•°æ®åŒæ­¥å™¨")
    
    // å‘é€åœæ­¢ä¿¡å·
    close(s.stopCh)
    
    // ç­‰å¾…æ‰€æœ‰å·¥ä½œåç¨‹ç»“æŸ
    s.workerWg.Wait()
    
    // å…³é—­é€šé“
    close(s.blockQueue)
    close(s.resultQueue)
    
    s.setStatus(StatusStopped)
    s.logger.Info("åŒºå—é“¾æ•°æ®åŒæ­¥å™¨å·²åœæ­¢")
    
    return nil
}

func (s *MainSynchronizer) setStatus(status SyncStatus) {
    s.mu.Lock()
    s.status = status
    s.mu.Unlock()
}

func (s *MainSynchronizer) GetStatus() SyncStatus {
    s.mu.RLock()
    defer s.mu.RUnlock()
    return s.status
}

func (s *MainSynchronizer) GetProgress() *SyncProgress {
    s.mu.RLock()
    defer s.mu.RUnlock()
    
    // å¤åˆ¶è¿›åº¦ä¿¡æ¯
    progress := *s.progress
    return &progress
}

// åŠ è½½åŒæ­¥è¿›åº¦
func (s *MainSynchronizer) loadProgress(ctx context.Context) error {
    lastBlock, err := s.storage.GetLastSyncedBlock(ctx)
    if err != nil {
        // å¦‚æœæ²¡æœ‰åŒæ­¥è®°å½•ï¼Œä»é…ç½®çš„èµ·å§‹å—å¼€å§‹
        s.progress.CurrentBlock = s.config.StartBlock
        s.logger.Info("ä»é…ç½®çš„èµ·å§‹å—å¼€å§‹åŒæ­¥", zap.Uint64("start_block", s.config.StartBlock))
        return nil
    }
    
    s.progress.CurrentBlock = lastBlock + 1
    s.logger.Info("ä»ä¸Šæ¬¡åŒæ­¥ä½ç½®ç»§ç»­", zap.Uint64("last_synced", lastBlock))
    return nil
}

// å¯åŠ¨å·¥ä½œåç¨‹
func (s *MainSynchronizer) startWorkers(ctx context.Context) {
    s.workers = make([]*SyncWorker, s.config.WorkerCount)
    
    for i := 0; i < s.config.WorkerCount; i++ {
        worker := NewSyncWorker(
            i,
            s.client,
            s.blockQueue,
            s.resultQueue,
            s.logger,
        )
        
        s.workers[i] = worker
        s.workerWg.Add(1)
        go worker.Start(ctx, &s.workerWg)
    }
    
    s.logger.Info("å¯åŠ¨åŒæ­¥å·¥ä½œåç¨‹", zap.Int("worker_count", s.config.WorkerCount))
}

// ä¸»åŒæ­¥å¾ªç¯
func (s *MainSynchronizer) syncLoop(ctx context.Context) {
    ticker := time.NewTicker(s.config.SyncInterval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-s.stopCh:
            return
        case <-ticker.C:
            if err := s.scheduleSyncBlocks(ctx); err != nil {
                s.logger.Error("è°ƒåº¦åŒæ­¥å—å¤±è´¥", zap.Error(err))
                s.errorCh <- err
            }
        case err := <-s.errorCh:
            s.logger.Error("åŒæ­¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯", zap.Error(err))
            // æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦ç»§ç»­åŒæ­¥
            if s.isFatalError(err) {
                s.setStatus(StatusError)
                return
            }
        }
    }
}

// è°ƒåº¦åŒæ­¥å—
func (s *MainSynchronizer) scheduleSyncBlocks(ctx context.Context) error {
    // è·å–æœ€æ–°åŒºå—å·
    latestBlock, err := s.client.GetLatestBlockNumber(ctx)
    if err != nil {
        return fmt.Errorf("è·å–æœ€æ–°åŒºå—å·å¤±è´¥: %w", err)
    }
    
    s.mu.Lock()
    s.progress.LatestBlock = latestBlock
    currentBlock := s.progress.CurrentBlock
    s.mu.Unlock()
    
    // æ£€æŸ¥æ˜¯å¦å·²ç»åŒæ­¥åˆ°æœ€æ–°
    if currentBlock >= latestBlock {
        if s.status != StatusCaughtUp {
            s.setStatus(StatusCaughtUp)
            s.logger.Info("å·²åŒæ­¥åˆ°æœ€æ–°åŒºå—", zap.Uint64("latest_block", latestBlock))
        }
        return nil
    }
    
    // è®¡ç®—éœ€è¦åŒæ­¥çš„åŒºå—èŒƒå›´
    endBlock := currentBlock + uint64(s.config.BatchSize) - 1
    if endBlock > latestBlock {
        endBlock = latestBlock
    }
    
    // å¦‚æœè®¾ç½®äº†ç»“æŸåŒºå—ï¼Œä¸è¶…è¿‡è¯¥åŒºå—
    if s.config.EndBlock > 0 && endBlock > s.config.EndBlock {
        endBlock = s.config.EndBlock
    }
    
    // å°†åŒºå—å·æ·»åŠ åˆ°é˜Ÿåˆ—
    for blockNum := currentBlock; blockNum <= endBlock; blockNum++ {
        select {
        case s.blockQueue <- blockNum:
        case <-ctx.Done():
            return ctx.Err()
        case <-s.stopCh:
            return nil
        }
    }
    
    s.logger.Debug("è°ƒåº¦åŒæ­¥å—",
        zap.Uint64("from", currentBlock),
        zap.Uint64("to", endBlock),
        zap.Uint64("latest", latestBlock),
    )
    
    return nil
}

// ç»“æœå¤„ç†å™¨
func (s *MainSynchronizer) resultProcessor(ctx context.Context) {
    batchResults := make([]*BlockResult, 0, s.config.BatchSize)
    batchTimer := time.NewTicker(time.Second * 5) // æ‰¹é‡å¤„ç†é—´éš”
    defer batchTimer.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-s.stopCh:
            return
        case result := <-s.resultQueue:
            if result.Error != nil {
                s.logger.Error("åŒºå—å¤„ç†å¤±è´¥",
                    zap.Uint64("block_number", result.BlockNumber),
                    zap.Error(result.Error),
                )
                // é‡æ–°åŠ å…¥é˜Ÿåˆ—è¿›è¡Œé‡è¯•
                s.requeueBlock(result.BlockNumber)
                continue
            }
            
            batchResults = append(batchResults, result)
            
            // æ‰¹é‡è¾¾åˆ°é™åˆ¶æˆ–å®šæ—¶è§¦å‘
            if len(batchResults) >= s.config.BatchSize {
                s.processBatch(ctx, batchResults)
                batchResults = batchResults[:0] // é‡ç½®åˆ‡ç‰‡
            }
            
        case <-batchTimer.C:
            if len(batchResults) > 0 {
                s.processBatch(ctx, batchResults)
                batchResults = batchResults[:0]
            }
        }
    }
}

// å¤„ç†æ‰¹é‡ç»“æœ
func (s *MainSynchronizer) processBatch(ctx context.Context, results []*BlockResult) {
    if len(results) == 0 {
        return
    }
    
    start := time.Now()
    
    // æ‰¹é‡ä¿å­˜åˆ°æ•°æ®åº“
    if err := s.storage.BatchSave(ctx, results); err != nil {
        s.logger.Error("æ‰¹é‡ä¿å­˜å¤±è´¥", zap.Error(err))
        // å•ç‹¬å¤„ç†æ¯ä¸ªç»“æœ
        for _, result := range results {
            if err := s.storage.Save(ctx, result); err != nil {
                s.logger.Error("ä¿å­˜åŒºå—å¤±è´¥",
                    zap.Uint64("block_number", result.BlockNumber),
                    zap.Error(err),
                )
                s.requeueBlock(result.BlockNumber)
            }
        }
        return
    }
    
    // æ›´æ–°åŒæ­¥è¿›åº¦
    s.updateProgress(results)
    
    s.logger.Debug("æ‰¹é‡å¤„ç†å®Œæˆ",
        zap.Int("batch_size", len(results)),
        zap.Duration("duration", time.Since(start)),
    )
}

// æ›´æ–°åŒæ­¥è¿›åº¦
func (s *MainSynchronizer) updateProgress(results []*BlockResult) {
    if len(results) == 0 {
        return
    }
    
    s.mu.Lock()
    defer s.mu.Unlock()
    
    // æ‰¾åˆ°æœ€å¤§çš„åŒºå—å·
    maxBlock := uint64(0)
    for _, result := range results {
        if result.BlockNumber > maxBlock {
            maxBlock = result.BlockNumber
        }
    }
    
    s.progress.CurrentBlock = maxBlock + 1
    s.progress.SyncedBlocks += uint64(len(results))
    
    // è®¡ç®—åŒæ­¥é€Ÿåº¦
    elapsed := time.Since(s.progress.StartTime)
    if elapsed > 0 {
        s.progress.BlocksPerSec = float64(s.progress.SyncedBlocks) / elapsed.Seconds()
    }
    
    // ä¼°ç®—å‰©ä½™æ—¶é—´
    if s.progress.LatestBlock > s.progress.CurrentBlock && s.progress.BlocksPerSec > 0 {
        remainingBlocks := s.progress.LatestBlock - s.progress.CurrentBlock
        estimatedSeconds := float64(remainingBlocks) / s.progress.BlocksPerSec
        s.progress.EstimatedTime = time.Duration(estimatedSeconds * float64(time.Second)).String()
    }
}

// è¿›åº¦æŠ¥å‘Šå™¨
func (s *MainSynchronizer) progressReporter(ctx context.Context) {
    ticker := time.NewTicker(s.config.ProgressReport)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-s.stopCh:
            return
        case <-ticker.C:
            progress := s.GetProgress()
            s.logger.Info("åŒæ­¥è¿›åº¦æŠ¥å‘Š",
                zap.Uint64("current_block", progress.CurrentBlock),
                zap.Uint64("latest_block", progress.LatestBlock),
                zap.Uint64("synced_blocks", progress.SyncedBlocks),
                zap.Float64("blocks_per_sec", progress.BlocksPerSec),
                zap.String("estimated_time", progress.EstimatedTime),
            )
        }
    }
}

// é‡æ–°æ’é˜ŸåŒºå—
func (s *MainSynchronizer) requeueBlock(blockNumber uint64) {
    // ç®€å•çš„é‡è¯•æœºåˆ¶ï¼Œå¯ä»¥æ‰©å±•ä¸ºæ›´å¤æ‚çš„é€€é¿ç­–ç•¥
    go func() {
        time.Sleep(s.config.RetryDelay)
        select {
        case s.blockQueue <- blockNumber:
        case <-s.stopCh:
        }
    }()
}

// åˆ¤æ–­æ˜¯å¦ä¸ºè‡´å‘½é”™è¯¯
func (s *MainSynchronizer) isFatalError(err error) bool {
    // æ ¹æ®é”™è¯¯ç±»å‹åˆ¤æ–­æ˜¯å¦ä¸ºè‡´å‘½é”™è¯¯
    // ä¾‹å¦‚ï¼šç½‘ç»œè¿æ¥é”™è¯¯é€šå¸¸ä¸æ˜¯è‡´å‘½çš„ï¼Œå¯ä»¥é‡è¯•
    // ä½†æ˜¯æ•°æ®åº“è¿æ¥é”™è¯¯å¯èƒ½æ˜¯è‡´å‘½çš„
    return false // ç®€åŒ–å®ç°
}
```

### 2. åŒæ­¥å·¥ä½œè€…

```go
package sync

import (
    "context"
    "fmt"
    "math/big"
    "sync"
    "time"
    
    "github.com/ethereum/go-ethereum/core/types"
    "go.uber.org/zap"
)

// åŒºå—ç»“æœ
type BlockResult struct {
    BlockNumber  uint64            `json:"block_number"`
    Block        *ProcessedBlock   `json:"block"`
    Transactions []*ProcessedTx    `json:"transactions"`
    Events       []*ProcessedEvent `json:"events"`
    Error        error             `json:"error,omitempty"`
    ProcessTime  time.Duration     `json:"process_time"`
}

// å¤„ç†åçš„åŒºå—æ•°æ®
type ProcessedBlock struct {
    Number       uint64    `json:"number"`
    Hash         string    `json:"hash"`
    ParentHash   string    `json:"parent_hash"`
    Timestamp    time.Time `json:"timestamp"`
    Miner        string    `json:"miner"`
    GasUsed      uint64    `json:"gas_used"`
    GasLimit     uint64    `json:"gas_limit"`
    Difficulty   string    `json:"difficulty"`
    TotalTxs     int       `json:"total_txs"`
}

// å¤„ç†åçš„äº¤æ˜“æ•°æ®
type ProcessedTx struct {
    Hash             string  `json:"hash"`
    BlockNumber      uint64  `json:"block_number"`
    TransactionIndex uint    `json:"transaction_index"`
    FromAddress      string  `json:"from_address"`
    ToAddress        *string `json:"to_address"`
    Value            string  `json:"value"`
    GasPrice         uint64  `json:"gas_price"`
    Gas              uint64  `json:"gas"`
    GasUsed          *uint64 `json:"gas_used"`
    Status           uint    `json:"status"`
    Input            string  `json:"input"`
    Nonce            uint64  `json:"nonce"`
}

// å¤„ç†åçš„äº‹ä»¶æ•°æ®
type ProcessedEvent struct {
    TransactionHash  string      `json:"transaction_hash"`
    Address          string      `json:"address"`
    Topics           []string    `json:"topics"`
    Data             string      `json:"data"`
    LogIndex         uint        `json:"log_index"`
    EventType        string      `json:"event_type"`
    DecodedData      interface{} `json:"decoded_data,omitempty"`
}

// åŒæ­¥å·¥ä½œè€…
type SyncWorker struct {
    id          int
    client      EthereumClient
    blockQueue  <-chan uint64
    resultQueue chan<- *BlockResult
    logger      *zap.Logger
    
    // äº‹ä»¶è§£æå™¨
    eventParsers map[string]EventParser
}

func NewSyncWorker(
    id int,
    client EthereumClient,
    blockQueue <-chan uint64,
    resultQueue chan<- *BlockResult,
    logger *zap.Logger,
) *SyncWorker {
    return &SyncWorker{
        id:           id,
        client:       client,
        blockQueue:   blockQueue,
        resultQueue:  resultQueue,
        logger:       logger,
        eventParsers: make(map[string]EventParser),
    }
}

func (w *SyncWorker) Start(ctx context.Context, wg *sync.WaitGroup) {
    defer wg.Done()
    
    w.logger.Debug("å¯åŠ¨åŒæ­¥å·¥ä½œè€…", zap.Int("worker_id", w.id))
    
    for {
        select {
        case <-ctx.Done():
            w.logger.Debug("å·¥ä½œè€…æ”¶åˆ°å–æ¶ˆä¿¡å·", zap.Int("worker_id", w.id))
            return
        case blockNumber, ok := <-w.blockQueue:
            if !ok {
                w.logger.Debug("åŒºå—é˜Ÿåˆ—å·²å…³é—­", zap.Int("worker_id", w.id))
                return
            }
            
            result := w.processBlock(ctx, blockNumber)
            
            select {
            case w.resultQueue <- result:
            case <-ctx.Done():
                return
            }
        }
    }
}

// å¤„ç†å•ä¸ªåŒºå—
func (w *SyncWorker) processBlock(ctx context.Context, blockNumber uint64) *BlockResult {
    start := time.Now()
    
    result := &BlockResult{
        BlockNumber: blockNumber,
        ProcessTime: 0,
    }
    
    // è·å–åŒºå—æ•°æ®
    block, err := w.client.GetBlockByNumber(ctx, big.NewInt(int64(blockNumber)))
    if err != nil {
        result.Error = fmt.Errorf("è·å–åŒºå— %d å¤±è´¥: %w", blockNumber, err)
        return result
    }
    
    // å¤„ç†åŒºå—åŸºç¡€ä¿¡æ¯
    result.Block = w.processBlockHeader(block)
    
    // å¤„ç†äº¤æ˜“
    transactions := make([]*ProcessedTx, 0, len(block.Transactions()))
    events := make([]*ProcessedEvent, 0)
    
    for _, tx := range block.Transactions() {
        processedTx, txEvents, err := w.processTransaction(ctx, tx, block)
        if err != nil {
            w.logger.Warn("å¤„ç†äº¤æ˜“å¤±è´¥",
                zap.String("tx_hash", tx.Hash().Hex()),
                zap.Error(err),
            )
            continue
        }
        
        transactions = append(transactions, processedTx)
        events = append(events, txEvents...)
    }
    
    result.Transactions = transactions
    result.Events = events
    result.ProcessTime = time.Since(start)
    
    w.logger.Debug("åŒºå—å¤„ç†å®Œæˆ",
        zap.Int("worker_id", w.id),
        zap.Uint64("block_number", blockNumber),
        zap.Int("tx_count", len(transactions)),
        zap.Int("event_count", len(events)),
        zap.Duration("process_time", result.ProcessTime),
    )
    
    return result
}

// å¤„ç†åŒºå—å¤´ä¿¡æ¯
func (w *SyncWorker) processBlockHeader(block *types.Block) *ProcessedBlock {
    return &ProcessedBlock{
        Number:     block.NumberU64(),
        Hash:       block.Hash().Hex(),
        ParentHash: block.ParentHash().Hex(),
        Timestamp:  time.Unix(int64(block.Time()), 0),
        Miner:      block.Coinbase().Hex(),
        GasUsed:    block.GasUsed(),
        GasLimit:   block.GasLimit(),
        Difficulty: block.Difficulty().String(),
        TotalTxs:   len(block.Transactions()),
    }
}

// å¤„ç†å•ä¸ªäº¤æ˜“
func (w *SyncWorker) processTransaction(
    ctx context.Context,
    tx *types.Transaction,
    block *types.Block,
) (*ProcessedTx, []*ProcessedEvent, error) {
    // è·å–äº¤æ˜“æ”¶æ®
    receipt, err := w.client.GetTransactionReceipt(ctx, tx.Hash())
    if err != nil {
        return nil, nil, fmt.Errorf("è·å–äº¤æ˜“æ”¶æ®å¤±è´¥: %w", err)
    }
    
    // è·å–å‘é€æ–¹åœ°å€
    from, err := types.Sender(types.NewEIP155Signer(tx.ChainId()), tx)
    if err != nil {
        return nil, nil, fmt.Errorf("è·å–å‘é€æ–¹åœ°å€å¤±è´¥: %w", err)
    }
    
    // æ„é€ äº¤æ˜“æ•°æ®
    var toAddress *string
    if tx.To() != nil {
        addr := tx.To().Hex()
        toAddress = &addr
    }
    
    processedTx := &ProcessedTx{
        Hash:             tx.Hash().Hex(),
        BlockNumber:      block.NumberU64(),
        TransactionIndex: w.getTransactionIndex(tx, block),
        FromAddress:      from.Hex(),
        ToAddress:        toAddress,
        Value:            tx.Value().String(),
        GasPrice:         tx.GasPrice().Uint64(),
        Gas:              tx.Gas(),
        GasUsed:          &receipt.GasUsed,
        Status:           uint(receipt.Status),
        Input:            fmt.Sprintf("0x%x", tx.Data()),
        Nonce:            tx.Nonce(),
    }
    
    // å¤„ç†äº‹ä»¶æ—¥å¿—
    events := make([]*ProcessedEvent, 0, len(receipt.Logs))
    for _, log := range receipt.Logs {
        event := w.processEventLog(log)
        events = append(events, event)
    }
    
    return processedTx, events, nil
}

// å¤„ç†äº‹ä»¶æ—¥å¿—
func (w *SyncWorker) processEventLog(log *types.Log) *ProcessedEvent {
    topics := make([]string, len(log.Topics))
    for i, topic := range log.Topics {
        topics[i] = topic.Hex()
    }
    
    event := &ProcessedEvent{
        TransactionHash: log.TxHash.Hex(),
        Address:         log.Address.Hex(),
        Topics:          topics,
        Data:            fmt.Sprintf("0x%x", log.Data),
        LogIndex:        log.Index,
        EventType:       "unknown",
    }
    
    // å°è¯•è§£æå·²çŸ¥äº‹ä»¶
    if parser, exists := w.eventParsers[log.Address.Hex()]; exists {
        if decoded, eventType := parser.Parse(log); decoded != nil {
            event.DecodedData = decoded
            event.EventType = eventType
        }
    }
    
    return event
}

// è·å–äº¤æ˜“åœ¨åŒºå—ä¸­çš„ç´¢å¼•
func (w *SyncWorker) getTransactionIndex(target *types.Transaction, block *types.Block) uint {
    for i, tx := range block.Transactions() {
        if tx.Hash() == target.Hash() {
            return uint(i)
        }
    }
    return 0
}

// æ³¨å†Œäº‹ä»¶è§£æå™¨
func (w *SyncWorker) RegisterEventParser(address string, parser EventParser) {
    w.eventParsers[address] = parser
}

// äº‹ä»¶è§£æå™¨æ¥å£
type EventParser interface {
    Parse(log *types.Log) (interface{}, string)
}

// ERC20 è½¬è´¦äº‹ä»¶è§£æå™¨ç¤ºä¾‹
type ERC20TransferParser struct{}

func (p *ERC20TransferParser) Parse(log *types.Log) (interface{}, string) {
    // æ£€æŸ¥æ˜¯å¦ä¸º Transfer äº‹ä»¶
    if len(log.Topics) != 3 || log.Topics[0].Hex() != "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef" {
        return nil, "unknown"
    }
    
    return map[string]interface{}{
        "from":   log.Topics[1].Hex(),
        "to":     log.Topics[2].Hex(),
        "amount": new(big.Int).SetBytes(log.Data).String(),
    }, "Transfer"
}
```

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦

### åŒæ­¥ç›‘æ§ç³»ç»Ÿ

```go
package monitor

import (
    "context"
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "go.uber.org/zap"
)

// åŒæ­¥ç›‘æ§å™¨
type SyncMonitor struct {
    metrics *SyncMetrics
    logger  *zap.Logger
    
    // å‘Šè­¦é…ç½®
    alertConfig *AlertConfig
}

type SyncMetrics struct {
    // åŒæ­¥è¿›åº¦æŒ‡æ ‡
    currentBlock     prometheus.Gauge
    latestBlock      prometheus.Gauge
    blocksPerSecond  prometheus.Gauge
    syncLag          prometheus.Gauge
    
    // æ€§èƒ½æŒ‡æ ‡
    blockProcessTime prometheus.Histogram
    batchSize        prometheus.Gauge
    queueSize        prometheus.Gauge
    workerCount      prometheus.Gauge
    
    // é”™è¯¯æŒ‡æ ‡
    syncErrors       prometheus.CounterVec
    retryCount       prometheus.CounterVec
    
    // æ•°æ®è´¨é‡æŒ‡æ ‡
    missedBlocks     prometheus.Counter
    duplicateBlocks  prometheus.Counter
    dataInconsistency prometheus.Counter
}

type AlertConfig struct {
    MaxSyncLag        time.Duration `yaml:"max_sync_lag"`
    MaxBlockTime      time.Duration `yaml:"max_block_time"`
    MaxErrorRate      float64       `yaml:"max_error_rate"`
    AlertWebhook      string        `yaml:"alert_webhook"`
}

func NewSyncMonitor(alertConfig *AlertConfig, logger *zap.Logger) *SyncMonitor {
    metrics := &SyncMetrics{
        currentBlock: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "sync_current_block",
            Help: "Current synced block number",
        }),
        latestBlock: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "sync_latest_block",
            Help: "Latest block number from blockchain",
        }),
        blocksPerSecond: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "sync_blocks_per_second",
            Help: "Blocks processed per second",
        }),
        syncLag: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "sync_lag_blocks",
            Help: "Number of blocks behind latest",
        }),
        blockProcessTime: prometheus.NewHistogram(prometheus.HistogramOpts{
            Name: "sync_block_process_duration_seconds",
            Help: "Time spent processing each block",
        }),
        batchSize: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "sync_batch_size",
            Help: "Current batch size for processing",
        }),
        queueSize: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "sync_queue_size",
            Help: "Current queue size",
        }),
        workerCount: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "sync_worker_count",
            Help: "Number of active sync workers",
        }),
        syncErrors: *prometheus.NewCounterVec(prometheus.CounterOpts{
            Name: "sync_errors_total",
            Help: "Total sync errors by type",
        }, []string{"error_type"}),
        retryCount: *prometheus.NewCounterVec(prometheus.CounterOpts{
            Name: "sync_retries_total",
            Help: "Total retry attempts by reason",
        }, []string{"reason"}),
        missedBlocks: prometheus.NewCounter(prometheus.CounterOpts{
            Name: "sync_missed_blocks_total",
            Help: "Total number of missed blocks",
        }),
        duplicateBlocks: prometheus.NewCounter(prometheus.CounterOpts{
            Name: "sync_duplicate_blocks_total",
            Help: "Total number of duplicate blocks",
        }),
        dataInconsistency: prometheus.NewCounter(prometheus.CounterOpts{
            Name: "sync_data_inconsistency_total",
            Help: "Total number of data inconsistencies detected",
        }),
    }
    
    // æ³¨å†ŒæŒ‡æ ‡
    prometheus.MustRegister(
        metrics.currentBlock,
        metrics.latestBlock,
        metrics.blocksPerSecond,
        metrics.syncLag,
        metrics.blockProcessTime,
        metrics.batchSize,
        metrics.queueSize,
        metrics.workerCount,
        metrics.syncErrors,
        metrics.retryCount,
        metrics.missedBlocks,
        metrics.duplicateBlocks,
        metrics.dataInconsistency,
    )
    
    return &SyncMonitor{
        metrics:     metrics,
        logger:      logger,
        alertConfig: alertConfig,
    }
}

// æ›´æ–°åŒæ­¥æŒ‡æ ‡
func (sm *SyncMonitor) UpdateSyncProgress(progress *SyncProgress) {
    sm.metrics.currentBlock.Set(float64(progress.CurrentBlock))
    sm.metrics.latestBlock.Set(float64(progress.LatestBlock))
    sm.metrics.blocksPerSecond.Set(progress.BlocksPerSec)
    
    lag := int64(progress.LatestBlock) - int64(progress.CurrentBlock)
    if lag < 0 {
        lag = 0
    }
    sm.metrics.syncLag.Set(float64(lag))
    
    // æ£€æŸ¥å‘Šè­¦æ¡ä»¶
    sm.checkAlerts(progress)
}

// è®°å½•åŒºå—å¤„ç†æ—¶é—´
func (sm *SyncMonitor) RecordBlockProcessTime(duration time.Duration) {
    sm.metrics.blockProcessTime.Observe(duration.Seconds())
}

// è®°å½•åŒæ­¥é”™è¯¯
func (sm *SyncMonitor) RecordSyncError(errorType string) {
    sm.metrics.syncErrors.WithLabelValues(errorType).Inc()
}

// è®°å½•é‡è¯•
func (sm *SyncMonitor) RecordRetry(reason string) {
    sm.metrics.retryCount.WithLabelValues(reason).Inc()
}

// æ£€æŸ¥å‘Šè­¦æ¡ä»¶
func (sm *SyncMonitor) checkAlerts(progress *SyncProgress) {
    // æ£€æŸ¥åŒæ­¥å»¶è¿Ÿ
    lag := int64(progress.LatestBlock) - int64(progress.CurrentBlock)
    if time.Duration(lag)*time.Second*12 > sm.alertConfig.MaxSyncLag { // å‡è®¾12ç§’å‡ºä¸€ä¸ªå—
        sm.sendAlert("sync_lag", fmt.Sprintf("åŒæ­¥å»¶è¿Ÿè¿‡å¤§: %d ä¸ªåŒºå—", lag))
    }
    
    // æ£€æŸ¥åŒºå—å¤„ç†é€Ÿåº¦
    if progress.BlocksPerSec > 0 && time.Duration(1/progress.BlocksPerSec*float64(time.Second)) > sm.alertConfig.MaxBlockTime {
        sm.sendAlert("slow_processing", fmt.Sprintf("åŒºå—å¤„ç†é€Ÿåº¦è¿‡æ…¢: %.2f blocks/sec", progress.BlocksPerSec))
    }
}

// å‘é€å‘Šè­¦
func (sm *SyncMonitor) sendAlert(alertType, message string) {
    sm.logger.Warn("è§¦å‘åŒæ­¥å‘Šè­¦",
        zap.String("alert_type", alertType),
        zap.String("message", message),
    )
    
    // å®é™…å®ç°ä¸­å¯ä»¥å‘é€åˆ° Slackã€é’‰é’‰ç­‰
    if sm.alertConfig.AlertWebhook != "" {
        go sm.sendWebhookAlert(alertType, message)
    }
}

// å‘é€ Webhook å‘Šè­¦
func (sm *SyncMonitor) sendWebhookAlert(alertType, message string) {
    // å®ç° webhook å‘Šè­¦é€»è¾‘
    // è¿™é‡Œæ˜¯ç¤ºä¾‹å®ç°
    sm.logger.Info("å‘é€webhookå‘Šè­¦", 
        zap.String("webhook", sm.alertConfig.AlertWebhook),
        zap.String("alert_type", alertType),
        zap.String("message", message),
    )
}
```

## ğŸ”§ é…ç½®ç¤ºä¾‹

### å®Œæ•´é…ç½®æ–‡ä»¶

```yaml
# config/sync_config.yaml
sync:
  # åŸºç¡€é…ç½®
  start_block: 18000000
  end_block: 0  # 0 è¡¨ç¤ºæŒç»­åŒæ­¥
  batch_size: 100
  worker_count: 5
  queue_size: 1000
  
  # æ—¶é—´é—´éš”
  sync_interval: "5s"
  progress_report: "30s"
  
  # é‡è¯•é…ç½®
  retry_limit: 3
  retry_delay: "1s"

# åŒºå—é“¾å®¢æˆ·ç«¯é…ç½®
blockchain:
  rpc_url: "https://eth-mainnet.alchemyapi.io/v2/YOUR_API_KEY"
  retry_count: 3
  retry_delay: "1s"
  request_timeout: "30s"
  max_concurrency: 10

# æ•°æ®åº“é…ç½®
database:
  host: "localhost"
  port: 3306
  username: "web3_user"
  password: "secure_password_123"
  database: "awesome_trade_blockchain"
  max_open_conns: 100
  max_idle_conns: 10
  conn_max_lifetime: "1h"
  conn_max_idle_time: "10m"

# ç›‘æ§å‘Šè­¦é…ç½®
alerts:
  max_sync_lag: "5m"      # æœ€å¤§åŒæ­¥å»¶è¿Ÿ
  max_block_time: "10s"   # æœ€å¤§åŒºå—å¤„ç†æ—¶é—´
  max_error_rate: 0.05    # æœ€å¤§é”™è¯¯ç‡ 5%
  alert_webhook: "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

# æ—¥å¿—é…ç½®
logging:
  level: "info"
  format: "json"
  output: ["stdout", "file"]
  file_path: "/var/log/web3-sync/sync.log"
  max_size: 100    # MB
  max_backups: 10
  max_age: 30      # days
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### æ‰¹é‡å¤„ç†ä¼˜åŒ–

```go
// ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†å™¨
type OptimizedBatchProcessor struct {
    batchSize     int
    flushInterval time.Duration
    buffer        []*BlockResult
    mu            sync.Mutex
    flushCh       chan struct{}
}

func (bp *OptimizedBatchProcessor) Add(result *BlockResult) {
    bp.mu.Lock()
    bp.buffer = append(bp.buffer, result)
    shouldFlush := len(bp.buffer) >= bp.batchSize
    bp.mu.Unlock()
    
    if shouldFlush {
        select {
        case bp.flushCh <- struct{}{}:
        default:
            // éé˜»å¡å‘é€
        }
    }
}

func (bp *OptimizedBatchProcessor) Start(ctx context.Context) {
    ticker := time.NewTicker(bp.flushInterval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            bp.flushAll()
            return
        case <-bp.flushCh:
            bp.flushBatch()
        case <-ticker.C:
            bp.flushBatch()
        }
    }
}
```

### å†…å­˜ä¼˜åŒ–

```go
// å¯¹è±¡æ± ä¼˜åŒ–å†…å­˜åˆ†é…
var blockResultPool = sync.Pool{
    New: func() interface{} {
        return &BlockResult{
            Transactions: make([]*ProcessedTx, 0, 100),
            Events:       make([]*ProcessedEvent, 0, 200),
        }
    },
}

func (w *SyncWorker) getBlockResult() *BlockResult {
    result := blockResultPool.Get().(*BlockResult)
    result.BlockNumber = 0
    result.Block = nil
    result.Transactions = result.Transactions[:0]
    result.Events = result.Events[:0]
    result.Error = nil
    result.ProcessTime = 0
    return result
}

func (w *SyncWorker) putBlockResult(result *BlockResult) {
    blockResultPool.Put(result)
}
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **åŒæ­¥é€Ÿåº¦æ…¢**
   - å¢åŠ å·¥ä½œåç¨‹æ•°é‡
   - ä¼˜åŒ–æ‰¹é‡å¤§å°
   - æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
   - ä½¿ç”¨æ›´å¿«çš„RPCèŠ‚ç‚¹

2. **å†…å­˜ä½¿ç”¨è¿‡é«˜**
   - å‡å°‘æ‰¹é‡å¤§å°
   - ä½¿ç”¨å¯¹è±¡æ± 
   - åŠæ—¶é‡Šæ”¾èµ„æº
   - æ£€æŸ¥å†…å­˜æ³„æ¼

3. **æ•°æ®ä¸ä¸€è‡´**
   - å®ç°æ•°æ®æ ¡éªŒ
   - æ£€æŸ¥åŒºå—é“¾é‡ç»„
   - ç¡®ä¿äº‹åŠ¡å®Œæ•´æ€§

4. **è¿æ¥è¶…æ—¶**
   - å¢åŠ é‡è¯•æ¬¡æ•°
   - ä½¿ç”¨è¿æ¥æ± 
   - æ£€æŸ¥ç½‘ç»œç¨³å®šæ€§

---

**æœ€åæ›´æ–°**: 2025-01-13  
**ç»´æŠ¤å›¢é˜Ÿ**: Awesome Trade å¼€å‘å›¢é˜Ÿ
