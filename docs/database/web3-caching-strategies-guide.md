# ğŸš€ Web3 ç¼“å­˜ç­–ç•¥æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

ç¼“å­˜æ˜¯ Web3 åº”ç”¨æ€§èƒ½ä¼˜åŒ–çš„å…³é”®æŠ€æœ¯ï¼Œæœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨åŒºå—é“¾åº”ç”¨ä¸­è®¾è®¡å’Œå®æ–½å¤šå±‚ç¼“å­˜æ¶æ„ï¼ŒåŒ…æ‹¬å†…å­˜ç¼“å­˜ã€åˆ†å¸ƒå¼ç¼“å­˜ã€æŸ¥è¯¢ç¼“å­˜ç­‰ç­–ç•¥ï¼Œä»¥æä¾›æ¯«ç§’çº§çš„æ•°æ®è®¿é—®æ€§èƒ½ã€‚

## ğŸ—ï¸ ç¼“å­˜æ¶æ„è®¾è®¡

### å¤šå±‚ç¼“å­˜æ¶æ„

```mermaid
graph TB
    A[å®¢æˆ·ç«¯è¯·æ±‚] --> B[åº”ç”¨å±‚ç¼“å­˜]
    B --> C[åˆ†å¸ƒå¼ç¼“å­˜Redis]
    C --> D[æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜]
    D --> E[MySQLæ•°æ®åº“]
    
    F[ç¼“å­˜é¢„çƒ­] --> B
    F --> C
    
    G[ç¼“å­˜å¤±æ•ˆ] --> B
    G --> C
    G --> D
    
    H[ç›‘æ§å‘Šè­¦] --> B
    H --> C
    H --> D
```

### ç¼“å­˜å±‚çº§è®¾è®¡

| ç¼“å­˜å±‚çº§ | æŠ€æœ¯æ–¹æ¡ˆ | å®¹é‡ | å“åº”æ—¶é—´ | é€‚ç”¨åœºæ™¯ |
|----------|----------|------|----------|----------|
| L1 - åº”ç”¨ç¼“å­˜ | sync.Map/BigCache | 100MB-1GB | <1ms | çƒ­ç‚¹æ•°æ®ã€è®¡ç®—ç»“æœ |
| L2 - åˆ†å¸ƒå¼ç¼“å­˜ | Redis Cluster | 10GB-100GB | 1-5ms | ä¼šè¯æ•°æ®ã€æŸ¥è¯¢ç»“æœ |
| L3 - æ•°æ®åº“ç¼“å­˜ | MySQL Query Cache | 1GB-10GB | 10-50ms | SQLæŸ¥è¯¢ç»“æœ |
| L4 - CDNç¼“å­˜ | CloudFlare/AWS | 1TB+ | 50-200ms | é™æ€èµ„æºã€APIå“åº” |

## ğŸ”§ ç¼“å­˜å®ç°

### 1. åº”ç”¨å±‚å†…å­˜ç¼“å­˜

```go
package cache

import (
    "context"
    "fmt"
    "sync"
    "time"
    "unsafe"
    
    "github.com/allegro/bigcache/v3"
)

// ç¼“å­˜æ¥å£
type Cache interface {
    Get(ctx context.Context, key string) ([]byte, error)
    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error
    Delete(ctx context.Context, key string) error
    Clear(ctx context.Context) error
    Stats() *CacheStats
}

// ç¼“å­˜ç»Ÿè®¡
type CacheStats struct {
    Hits         int64   `json:"hits"`
    Misses       int64   `json:"misses"`
    HitRate      float64 `json:"hit_rate"`
    Size         int64   `json:"size"`
    Entries      int64   `json:"entries"`
    Memory       int64   `json:"memory_bytes"`
    Evictions    int64   `json:"evictions"`
}

// å†…å­˜ç¼“å­˜é…ç½®
type MemoryCacheConfig struct {
    MaxSize      int           `yaml:"max_size"`      // æœ€å¤§æ¡ç›®æ•°
    TTL          time.Duration `yaml:"ttl"`           // é»˜è®¤TTL
    CleanupRate  time.Duration `yaml:"cleanup_rate"`  // æ¸…ç†é¢‘ç‡
    MaxMemoryMB  int           `yaml:"max_memory_mb"` // æœ€å¤§å†…å­˜MB
}

// å†…å­˜ç¼“å­˜å®ç°
type MemoryCache struct {
    config    *MemoryCacheConfig
    bigCache  *bigcache.BigCache
    
    // ç»Ÿè®¡ä¿¡æ¯
    mu        sync.RWMutex
    stats     *CacheStats
    
    // ç›‘æ§
    monitor   *CacheMonitor
}

func NewMemoryCache(config *MemoryCacheConfig) (*MemoryCache, error) {
    bigCacheConfig := bigcache.DefaultConfig(config.TTL)
    bigCacheConfig.Shards = 1024
    bigCacheConfig.MaxEntriesInWindow = config.MaxSize
    bigCacheConfig.MaxEntrySize = 500
    bigCacheConfig.Verbose = false
    bigCacheConfig.HardMaxCacheSize = config.MaxMemoryMB
    
    bc, err := bigcache.NewBigCache(bigCacheConfig)
    if err != nil {
        return nil, fmt.Errorf("åˆ›å»ºBigCacheå¤±è´¥: %w", err)
    }
    
    mc := &MemoryCache{
        config:   config,
        bigCache: bc,
        stats: &CacheStats{},
        monitor:  NewCacheMonitor("memory"),
    }
    
    // å¯åŠ¨ç»Ÿè®¡æ›´æ–°
    go mc.updateStats()
    
    return mc, nil
}

func (mc *MemoryCache) Get(ctx context.Context, key string) ([]byte, error) {
    start := time.Now()
    defer func() {
        mc.monitor.RecordLatency("get", time.Since(start))
    }()
    
    data, err := mc.bigCache.Get(key)
    
    mc.mu.Lock()
    if err == nil {
        mc.stats.Hits++
        mc.monitor.RecordHit()
    } else {
        mc.stats.Misses++
        mc.monitor.RecordMiss()
    }
    mc.mu.Unlock()
    
    if err != nil {
        if err == bigcache.ErrEntryNotFound {
            return nil, ErrCacheKeyNotFound
        }
        return nil, fmt.Errorf("è·å–ç¼“å­˜å¤±è´¥: %w", err)
    }
    
    return data, nil
}

func (mc *MemoryCache) Set(ctx context.Context, key string, value []byte, ttl time.Duration) error {
    start := time.Now()
    defer func() {
        mc.monitor.RecordLatency("set", time.Since(start))
    }()
    
    if err := mc.bigCache.Set(key, value); err != nil {
        mc.monitor.RecordError("set")
        return fmt.Errorf("è®¾ç½®ç¼“å­˜å¤±è´¥: %w", err)
    }
    
    return nil
}

func (mc *MemoryCache) Delete(ctx context.Context, key string) error {
    start := time.Now()
    defer func() {
        mc.monitor.RecordLatency("delete", time.Since(start))
    }()
    
    if err := mc.bigCache.Delete(key); err != nil {
        return fmt.Errorf("åˆ é™¤ç¼“å­˜å¤±è´¥: %w", err)
    }
    
    return nil
}

func (mc *MemoryCache) Clear(ctx context.Context) error {
    mc.bigCache.Reset()
    
    mc.mu.Lock()
    mc.stats = &CacheStats{}
    mc.mu.Unlock()
    
    return nil
}

func (mc *MemoryCache) Stats() *CacheStats {
    mc.mu.RLock()
    defer mc.mu.RUnlock()
    
    stats := *mc.stats
    if stats.Hits+stats.Misses > 0 {
        stats.HitRate = float64(stats.Hits) / float64(stats.Hits+stats.Misses)
    }
    
    // ä» BigCache è·å–å®æ—¶ç»Ÿè®¡
    bcStats := mc.bigCache.Stats()
    stats.Entries = int64(bcStats.Hits + bcStats.Misses) // è¿‘ä¼¼å€¼
    
    return &stats
}

// å®šæœŸæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (mc *MemoryCache) updateStats() {
    ticker := time.NewTicker(time.Minute)
    defer ticker.Stop()
    
    for range ticker.C {
        bcStats := mc.bigCache.Stats()
        
        mc.mu.Lock()
        mc.stats.Size = int64(mc.bigCache.Len())
        mc.stats.Memory = int64(unsafe.Sizeof(mc.bigCache)) + int64(mc.bigCache.Capacity())
        mc.mu.Unlock()
        
        // æ›´æ–°ç›‘æ§æŒ‡æ ‡
        mc.monitor.UpdateStats(mc.Stats())
    }
}

// ç¼“å­˜é”™è¯¯å®šä¹‰
var (
    ErrCacheKeyNotFound = fmt.Errorf("ç¼“å­˜é”®ä¸å­˜åœ¨")
    ErrCacheExpired     = fmt.Errorf("ç¼“å­˜å·²è¿‡æœŸ")
)
```

### 2. Redis åˆ†å¸ƒå¼ç¼“å­˜

```go
package cache

import (
    "context"
    "encoding/json"
    "fmt"
    "time"
    
    "github.com/go-redis/redis/v8"
    "go.uber.org/zap"
)

// Redisç¼“å­˜é…ç½®
type RedisConfig struct {
    Addr         string        `yaml:"addr"`
    Password     string        `yaml:"password"`
    DB           int           `yaml:"db"`
    PoolSize     int           `yaml:"pool_size"`
    MinIdleConns int           `yaml:"min_idle_conns"`
    MaxRetries   int           `yaml:"max_retries"`
    DialTimeout  time.Duration `yaml:"dial_timeout"`
    ReadTimeout  time.Duration `yaml:"read_timeout"`
    WriteTimeout time.Duration `yaml:"write_timeout"`
}

// Redisåˆ†å¸ƒå¼ç¼“å­˜
type RedisCache struct {
    client  *redis.Client
    config  *RedisConfig
    logger  *zap.Logger
    monitor *CacheMonitor
    
    // åºåˆ—åŒ–å™¨
    serializer Serializer
}

func NewRedisCache(config *RedisConfig, logger *zap.Logger) (*RedisCache, error) {
    client := redis.NewClient(&redis.Options{
        Addr:         config.Addr,
        Password:     config.Password,
        DB:           config.DB,
        PoolSize:     config.PoolSize,
        MinIdleConns: config.MinIdleConns,
        MaxRetries:   config.MaxRetries,
        DialTimeout:  config.DialTimeout,
        ReadTimeout:  config.ReadTimeout,
        WriteTimeout: config.WriteTimeout,
    })
    
    // æµ‹è¯•è¿æ¥
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    if err := client.Ping(ctx).Err(); err != nil {
        return nil, fmt.Errorf("Redisè¿æ¥æµ‹è¯•å¤±è´¥: %w", err)
    }
    
    rc := &RedisCache{
        client:     client,
        config:     config,
        logger:     logger,
        monitor:    NewCacheMonitor("redis"),
        serializer: &JSONSerializer{},
    }
    
    logger.Info("Redisç¼“å­˜åˆå§‹åŒ–æˆåŠŸ", zap.String("addr", config.Addr))
    return rc, nil
}

func (rc *RedisCache) Get(ctx context.Context, key string) ([]byte, error) {
    start := time.Now()
    defer func() {
        rc.monitor.RecordLatency("get", time.Since(start))
    }()
    
    result, err := rc.client.Get(ctx, key).Result()
    if err != nil {
        if err == redis.Nil {
            rc.monitor.RecordMiss()
            return nil, ErrCacheKeyNotFound
        }
        rc.monitor.RecordError("get")
        return nil, fmt.Errorf("Redis GETå¤±è´¥: %w", err)
    }
    
    rc.monitor.RecordHit()
    return []byte(result), nil
}

func (rc *RedisCache) Set(ctx context.Context, key string, value []byte, ttl time.Duration) error {
    start := time.Now()
    defer func() {
        rc.monitor.RecordLatency("set", time.Since(start))
    }()
    
    err := rc.client.Set(ctx, key, value, ttl).Err()
    if err != nil {
        rc.monitor.RecordError("set")
        return fmt.Errorf("Redis SETå¤±è´¥: %w", err)
    }
    
    return nil
}

func (rc *RedisCache) Delete(ctx context.Context, key string) error {
    start := time.Now()
    defer func() {
        rc.monitor.RecordLatency("delete", time.Since(start))
    }()
    
    err := rc.client.Del(ctx, key).Err()
    if err != nil {
        rc.monitor.RecordError("delete")
        return fmt.Errorf("Redis DELå¤±è´¥: %w", err)
    }
    
    return nil
}

func (rc *RedisCache) Clear(ctx context.Context) error {
    start := time.Now()
    defer func() {
        rc.monitor.RecordLatency("clear", time.Since(start))
    }()
    
    err := rc.client.FlushDB(ctx).Err()
    if err != nil {
        rc.monitor.RecordError("clear")
        return fmt.Errorf("Redis FLUSHDBå¤±è´¥: %w", err)
    }
    
    return nil
}

// æ‰¹é‡æ“ä½œ
func (rc *RedisCache) MGet(ctx context.Context, keys []string) ([][]byte, error) {
    start := time.Now()
    defer func() {
        rc.monitor.RecordLatency("mget", time.Since(start))
    }()
    
    results, err := rc.client.MGet(ctx, keys...).Result()
    if err != nil {
        rc.monitor.RecordError("mget")
        return nil, fmt.Errorf("Redis MGETå¤±è´¥: %w", err)
    }
    
    values := make([][]byte, len(results))
    for i, result := range results {
        if result != nil {
            if str, ok := result.(string); ok {
                values[i] = []byte(str)
                rc.monitor.RecordHit()
            }
        } else {
            rc.monitor.RecordMiss()
        }
    }
    
    return values, nil
}

func (rc *RedisCache) MSet(ctx context.Context, pairs map[string]interface{}, ttl time.Duration) error {
    start := time.Now()
    defer func() {
        rc.monitor.RecordLatency("mset", time.Since(start))
    }()
    
    pipe := rc.client.Pipeline()
    
    for key, value := range pairs {
        pipe.Set(ctx, key, value, ttl)
    }
    
    _, err := pipe.Exec(ctx)
    if err != nil {
        rc.monitor.RecordError("mset")
        return fmt.Errorf("Redis Pipeline MSETå¤±è´¥: %w", err)
    }
    
    return nil
}

// é«˜çº§åŠŸèƒ½ï¼šåˆ†å¸ƒå¼é”
func (rc *RedisCache) Lock(ctx context.Context, key string, expiration time.Duration) (bool, error) {
    return rc.client.SetNX(ctx, key, "locked", expiration).Result()
}

func (rc *RedisCache) Unlock(ctx context.Context, key string) error {
    return rc.client.Del(ctx, key).Err()
}

// å‘å¸ƒè®¢é˜…
func (rc *RedisCache) Publish(ctx context.Context, channel string, message interface{}) error {
    data, err := rc.serializer.Serialize(message)
    if err != nil {
        return fmt.Errorf("åºåˆ—åŒ–æ¶ˆæ¯å¤±è´¥: %w", err)
    }
    
    return rc.client.Publish(ctx, channel, data).Err()
}

func (rc *RedisCache) Subscribe(ctx context.Context, channels ...string) *redis.PubSub {
    return rc.client.Subscribe(ctx, channels...)
}

// è·å–Redisç»Ÿè®¡ä¿¡æ¯
func (rc *RedisCache) Stats() *CacheStats {
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    info, err := rc.client.Info(ctx).Result()
    if err != nil {
        rc.logger.Error("è·å–Redisç»Ÿè®¡ä¿¡æ¯å¤±è´¥", zap.Error(err))
        return &CacheStats{}
    }
    
    stats := &CacheStats{}
    
    // è§£æRedis INFOè¾“å‡º
    // è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…éœ€è¦è§£æå®Œæ•´çš„INFOè¾“å‡º
    poolStats := rc.client.PoolStats()
    stats.Entries = int64(poolStats.TotalConns)
    
    return stats
}

// åºåˆ—åŒ–æ¥å£
type Serializer interface {
    Serialize(v interface{}) ([]byte, error)
    Deserialize(data []byte, v interface{}) error
}

// JSONåºåˆ—åŒ–å™¨
type JSONSerializer struct{}

func (j *JSONSerializer) Serialize(v interface{}) ([]byte, error) {
    return json.Marshal(v)
}

func (j *JSONSerializer) Deserialize(data []byte, v interface{}) error {
    return json.Unmarshal(data, v)
}
```

### 3. æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨

```go
package cache

import (
    "context"
    "fmt"
    "strings"
    "time"
    
    "go.uber.org/zap"
)

// ç¼“å­˜ç®¡ç†å™¨é…ç½®
type ManagerConfig struct {
    L1Config    *MemoryCacheConfig `yaml:"l1_config"`
    L2Config    *RedisConfig       `yaml:"l2_config"`
    DefaultTTL  time.Duration      `yaml:"default_ttl"`
    WriteThrough bool              `yaml:"write_through"`
    WriteBack    bool              `yaml:"write_back"`
}

// æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨
type SmartCacheManager struct {
    l1Cache  Cache  // å†…å­˜ç¼“å­˜
    l2Cache  Cache  // Redisç¼“å­˜
    config   *ManagerConfig
    logger   *zap.Logger
    
    // ç¼“å­˜ç­–ç•¥
    strategies map[string]*CacheStrategy
}

// ç¼“å­˜ç­–ç•¥
type CacheStrategy struct {
    TTL          time.Duration `json:"ttl"`
    UseL1        bool         `json:"use_l1"`
    UseL2        bool         `json:"use_l2"`
    WriteThrough bool         `json:"write_through"`
    WriteBack    bool         `json:"write_back"`
    Priority     int          `json:"priority"`  // ç¼“å­˜ä¼˜å…ˆçº§
}

func NewSmartCacheManager(config *ManagerConfig, logger *zap.Logger) (*SmartCacheManager, error) {
    // åˆå§‹åŒ–L1ç¼“å­˜
    l1Cache, err := NewMemoryCache(config.L1Config)
    if err != nil {
        return nil, fmt.Errorf("åˆå§‹åŒ–L1ç¼“å­˜å¤±è´¥: %w", err)
    }
    
    // åˆå§‹åŒ–L2ç¼“å­˜
    l2Cache, err := NewRedisCache(config.L2Config, logger)
    if err != nil {
        return nil, fmt.Errorf("åˆå§‹åŒ–L2ç¼“å­˜å¤±è´¥: %w", err)
    }
    
    scm := &SmartCacheManager{
        l1Cache:    l1Cache,
        l2Cache:    l2Cache,
        config:     config,
        logger:     logger,
        strategies: make(map[string]*CacheStrategy),
    }
    
    // åˆå§‹åŒ–é»˜è®¤ç­–ç•¥
    scm.initDefaultStrategies()
    
    logger.Info("æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    return scm, nil
}

// åˆå§‹åŒ–é»˜è®¤ç¼“å­˜ç­–ç•¥
func (scm *SmartCacheManager) initDefaultStrategies() {
    // åŒºå—æ•°æ®ï¼šé•¿æœŸç¼“å­˜ï¼Œä½¿ç”¨åŒå±‚
    scm.strategies["block:*"] = &CacheStrategy{
        TTL:          24 * time.Hour,
        UseL1:        true,
        UseL2:        true,
        WriteThrough: true,
        WriteBack:    false,
        Priority:     1,
    }
    
    // äº¤æ˜“æ•°æ®ï¼šä¸­æœŸç¼“å­˜ï¼Œä¼˜å…ˆL2
    scm.strategies["tx:*"] = &CacheStrategy{
        TTL:          6 * time.Hour,
        UseL1:        false,
        UseL2:        true,
        WriteThrough: true,
        WriteBack:    false,
        Priority:     2,
    }
    
    // ç”¨æˆ·ä¼šè¯ï¼šçŸ­æœŸç¼“å­˜ï¼Œä¼˜å…ˆL1
    scm.strategies["session:*"] = &CacheStrategy{
        TTL:          30 * time.Minute,
        UseL1:        true,
        UseL2:        false,
        WriteThrough: false,
        WriteBack:    true,
        Priority:     3,
    }
    
    // APIå“åº”ï¼šçŸ­æœŸç¼“å­˜ï¼ŒåŒå±‚
    scm.strategies["api:*"] = &CacheStrategy{
        TTL:          5 * time.Minute,
        UseL1:        true,
        UseL2:        true,
        WriteThrough: false,
        WriteBack:    true,
        Priority:     2,
    }
    
    // è®¡ç®—ç»“æœï¼šé•¿æœŸç¼“å­˜ï¼ŒåŒå±‚
    scm.strategies["compute:*"] = &CacheStrategy{
        TTL:          12 * time.Hour,
        UseL1:        true,
        UseL2:        true,
        WriteThrough: true,
        WriteBack:    false,
        Priority:     1,
    }
}

// æ™ºèƒ½è·å–
func (scm *SmartCacheManager) Get(ctx context.Context, key string) ([]byte, error) {
    strategy := scm.getStrategy(key)
    
    // å°è¯•L1ç¼“å­˜
    if strategy.UseL1 {
        if data, err := scm.l1Cache.Get(ctx, key); err == nil {
            scm.logger.Debug("L1ç¼“å­˜å‘½ä¸­", zap.String("key", key))
            return data, nil
        }
    }
    
    // å°è¯•L2ç¼“å­˜
    if strategy.UseL2 {
        if data, err := scm.l2Cache.Get(ctx, key); err == nil {
            scm.logger.Debug("L2ç¼“å­˜å‘½ä¸­", zap.String("key", key))
            
            // å›å†™åˆ°L1ç¼“å­˜
            if strategy.UseL1 {
                go func() {
                    if err := scm.l1Cache.Set(ctx, key, data, strategy.TTL); err != nil {
                        scm.logger.Warn("L1ç¼“å­˜å›å†™å¤±è´¥", zap.String("key", key), zap.Error(err))
                    }
                }()
            }
            
            return data, nil
        }
    }
    
    return nil, ErrCacheKeyNotFound
}

// æ™ºèƒ½è®¾ç½®
func (scm *SmartCacheManager) Set(ctx context.Context, key string, value []byte, ttl time.Duration) error {
    strategy := scm.getStrategy(key)
    
    if ttl == 0 {
        ttl = strategy.TTL
    }
    
    var l1Err, l2Err error
    
    // å†™å…¥L1ç¼“å­˜
    if strategy.UseL1 {
        l1Err = scm.l1Cache.Set(ctx, key, value, ttl)
        if l1Err != nil {
            scm.logger.Warn("L1ç¼“å­˜å†™å…¥å¤±è´¥", zap.String("key", key), zap.Error(l1Err))
        }
    }
    
    // å†™å…¥L2ç¼“å­˜
    if strategy.UseL2 {
        l2Err = scm.l2Cache.Set(ctx, key, value, ttl)
        if l2Err != nil {
            scm.logger.Warn("L2ç¼“å­˜å†™å…¥å¤±è´¥", zap.String("key", key), zap.Error(l2Err))
        }
    }
    
    // æ ¹æ®ç­–ç•¥å†³å®šé”™è¯¯å¤„ç†
    if strategy.WriteThrough {
        // å†™ç©¿æ¨¡å¼ï¼šä»»ä½•å±‚å¤±è´¥éƒ½è¿”å›é”™è¯¯
        if l1Err != nil || l2Err != nil {
            return fmt.Errorf("ç¼“å­˜å†™å…¥å¤±è´¥: L1=%v, L2=%v", l1Err, l2Err)
        }
    }
    
    return nil
}

// æ™ºèƒ½åˆ é™¤
func (scm *SmartCacheManager) Delete(ctx context.Context, key string) error {
    strategy := scm.getStrategy(key)
    
    var errors []error
    
    if strategy.UseL1 {
        if err := scm.l1Cache.Delete(ctx, key); err != nil {
            errors = append(errors, fmt.Errorf("L1åˆ é™¤å¤±è´¥: %w", err))
        }
    }
    
    if strategy.UseL2 {
        if err := scm.l2Cache.Delete(ctx, key); err != nil {
            errors = append(errors, fmt.Errorf("L2åˆ é™¤å¤±è´¥: %w", err))
        }
    }
    
    if len(errors) > 0 {
        return fmt.Errorf("ç¼“å­˜åˆ é™¤å¤±è´¥: %v", errors)
    }
    
    return nil
}

// è·å–ç¼“å­˜ç­–ç•¥
func (scm *SmartCacheManager) getStrategy(key string) *CacheStrategy {
    // æŒ‰ç…§ä¼˜å…ˆçº§åŒ¹é…ç­–ç•¥
    for pattern, strategy := range scm.strategies {
        if scm.matchPattern(pattern, key) {
            return strategy
        }
    }
    
    // è¿”å›é»˜è®¤ç­–ç•¥
    return &CacheStrategy{
        TTL:          scm.config.DefaultTTL,
        UseL1:        true,
        UseL2:        true,
        WriteThrough: scm.config.WriteThrough,
        WriteBack:    scm.config.WriteBack,
        Priority:     5,
    }
}

// ç®€å•æ¨¡å¼åŒ¹é…
func (scm *SmartCacheManager) matchPattern(pattern, key string) bool {
    if pattern == "*" {
        return true
    }
    
    if strings.HasSuffix(pattern, "*") {
        prefix := pattern[:len(pattern)-1]
        return strings.HasPrefix(key, prefix)
    }
    
    if strings.HasPrefix(pattern, "*") {
        suffix := pattern[1:]
        return strings.HasSuffix(key, suffix)
    }
    
    return pattern == key
}

// æ³¨å†Œè‡ªå®šä¹‰ç­–ç•¥
func (scm *SmartCacheManager) RegisterStrategy(pattern string, strategy *CacheStrategy) {
    scm.strategies[pattern] = strategy
    scm.logger.Info("æ³¨å†Œç¼“å­˜ç­–ç•¥", 
        zap.String("pattern", pattern),
        zap.Duration("ttl", strategy.TTL),
        zap.Bool("use_l1", strategy.UseL1),
        zap.Bool("use_l2", strategy.UseL2),
    )
}

// é¢„çƒ­ç¼“å­˜
func (scm *SmartCacheManager) Warmup(ctx context.Context, warmupData map[string]interface{}) error {
    scm.logger.Info("å¼€å§‹ç¼“å­˜é¢„çƒ­", zap.Int("items", len(warmupData)))
    
    for key, value := range warmupData {
        data, err := scm.serialize(value)
        if err != nil {
            scm.logger.Warn("åºåˆ—åŒ–é¢„çƒ­æ•°æ®å¤±è´¥", zap.String("key", key), zap.Error(err))
            continue
        }
        
        if err := scm.Set(ctx, key, data, 0); err != nil {
            scm.logger.Warn("é¢„çƒ­ç¼“å­˜å¤±è´¥", zap.String("key", key), zap.Error(err))
        }
    }
    
    scm.logger.Info("ç¼“å­˜é¢„çƒ­å®Œæˆ")
    return nil
}

// ç¼“å­˜ç»Ÿè®¡
func (scm *SmartCacheManager) Stats() map[string]*CacheStats {
    return map[string]*CacheStats{
        "l1": scm.l1Cache.Stats(),
        "l2": scm.l2Cache.Stats(),
    }
}

// å¥åº·æ£€æŸ¥
func (scm *SmartCacheManager) HealthCheck(ctx context.Context) error {
    // æµ‹è¯•L1ç¼“å­˜
    testKey := "health_check"
    testValue := []byte("ok")
    
    if err := scm.l1Cache.Set(ctx, testKey, testValue, time.Minute); err != nil {
        return fmt.Errorf("L1ç¼“å­˜å¥åº·æ£€æŸ¥å¤±è´¥: %w", err)
    }
    
    if _, err := scm.l1Cache.Get(ctx, testKey); err != nil {
        return fmt.Errorf("L1ç¼“å­˜è¯»å–æ£€æŸ¥å¤±è´¥: %w", err)
    }
    
    scm.l1Cache.Delete(ctx, testKey)
    
    // æµ‹è¯•L2ç¼“å­˜
    if err := scm.l2Cache.Set(ctx, testKey, testValue, time.Minute); err != nil {
        return fmt.Errorf("L2ç¼“å­˜å¥åº·æ£€æŸ¥å¤±è´¥: %w", err)
    }
    
    if _, err := scm.l2Cache.Get(ctx, testKey); err != nil {
        return fmt.Errorf("L2ç¼“å­˜è¯»å–æ£€æŸ¥å¤±è´¥: %w", err)
    }
    
    scm.l2Cache.Delete(ctx, testKey)
    
    return nil
}

func (scm *SmartCacheManager) serialize(v interface{}) ([]byte, error) {
    serializer := &JSONSerializer{}
    return serializer.Serialize(v)
}
```

### 4. ç¼“å­˜ç›‘æ§

```go
package cache

import (
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
)

// ç¼“å­˜ç›‘æ§å™¨
type CacheMonitor struct {
    name string
    
    // PrometheusæŒ‡æ ‡
    hitCount     prometheus.Counter
    missCount    prometheus.Counter
    errorCount   prometheus.CounterVec
    latency      prometheus.HistogramVec
    memoryUsage  prometheus.Gauge
    entryCount   prometheus.Gauge
}

func NewCacheMonitor(cacheName string) *CacheMonitor {
    monitor := &CacheMonitor{
        name: cacheName,
        hitCount: prometheus.NewCounter(prometheus.CounterOpts{
            Name: cacheName + "_hits_total",
            Help: "Total number of cache hits",
        }),
        missCount: prometheus.NewCounter(prometheus.CounterOpts{
            Name: cacheName + "_misses_total", 
            Help: "Total number of cache misses",
        }),
        errorCount: *prometheus.NewCounterVec(prometheus.CounterOpts{
            Name: cacheName + "_errors_total",
            Help: "Total number of cache errors",
        }, []string{"operation"}),
        latency: *prometheus.NewHistogramVec(prometheus.HistogramOpts{
            Name: cacheName + "_operation_duration_seconds",
            Help: "Cache operation duration in seconds",
        }, []string{"operation"}),
        memoryUsage: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: cacheName + "_memory_usage_bytes",
            Help: "Cache memory usage in bytes",
        }),
        entryCount: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: cacheName + "_entries_total",
            Help: "Total number of cache entries",
        }),
    }
    
    // æ³¨å†ŒæŒ‡æ ‡
    prometheus.MustRegister(
        monitor.hitCount,
        monitor.missCount,
        monitor.errorCount,
        monitor.latency,
        monitor.memoryUsage,
        monitor.entryCount,
    )
    
    return monitor
}

func (cm *CacheMonitor) RecordHit() {
    cm.hitCount.Inc()
}

func (cm *CacheMonitor) RecordMiss() {
    cm.missCount.Inc()
}

func (cm *CacheMonitor) RecordError(operation string) {
    cm.errorCount.WithLabelValues(operation).Inc()
}

func (cm *CacheMonitor) RecordLatency(operation string, duration time.Duration) {
    cm.latency.WithLabelValues(operation).Observe(duration.Seconds())
}

func (cm *CacheMonitor) UpdateStats(stats *CacheStats) {
    cm.memoryUsage.Set(float64(stats.Memory))
    cm.entryCount.Set(float64(stats.Entries))
}
```

## ğŸ¯ Web3 ç‰¹å®šç¼“å­˜ç­–ç•¥

### åŒºå—é“¾æ•°æ®ç¼“å­˜

```go
// åŒºå—é“¾æ•°æ®ç¼“å­˜ä¸“ç”¨åŒ…è£…å™¨
type Web3CacheWrapper struct {
    cache  *SmartCacheManager
    logger *zap.Logger
}

// ç¼“å­˜åŒºå—æ•°æ®
func (w *Web3CacheWrapper) CacheBlock(ctx context.Context, block *models.Block) error {
    key := fmt.Sprintf("block:%d", block.Number)
    data, err := json.Marshal(block)
    if err != nil {
        return fmt.Errorf("åºåˆ—åŒ–åŒºå—å¤±è´¥: %w", err)
    }
    
    // åŒºå—æ•°æ®æ°¸ä¹…ç¼“å­˜ï¼ˆé™¤éæ‰‹åŠ¨æ¸…ç†ï¼‰
    return w.cache.Set(ctx, key, data, 0)
}

// ç¼“å­˜äº¤æ˜“æ•°æ®
func (w *Web3CacheWrapper) CacheTransaction(ctx context.Context, tx *models.Transaction) error {
    key := fmt.Sprintf("tx:%s", tx.Hash)
    data, err := json.Marshal(tx)
    if err != nil {
        return fmt.Errorf("åºåˆ—åŒ–äº¤æ˜“å¤±è´¥: %w", err)
    }
    
    // äº¤æ˜“æ•°æ®ç¼“å­˜6å°æ—¶
    return w.cache.Set(ctx, key, data, 6*time.Hour)
}

// ç¼“å­˜ä»£å¸ä»·æ ¼
func (w *Web3CacheWrapper) CacheTokenPrice(ctx context.Context, tokenAddr string, price *TokenPrice) error {
    key := fmt.Sprintf("price:%s", tokenAddr)
    data, err := json.Marshal(price)
    if err != nil {
        return fmt.Errorf("åºåˆ—åŒ–ä»·æ ¼å¤±è´¥: %w", err)
    }
    
    // ä»·æ ¼æ•°æ®ç¼“å­˜5åˆ†é’Ÿ
    return w.cache.Set(ctx, key, data, 5*time.Minute)
}

// ç¼“å­˜DeFiåè®®æ•°æ®
func (w *Web3CacheWrapper) CacheProtocolData(ctx context.Context, protocol string, data interface{}) error {
    key := fmt.Sprintf("protocol:%s", protocol)
    jsonData, err := json.Marshal(data)
    if err != nil {
        return fmt.Errorf("åºåˆ—åŒ–åè®®æ•°æ®å¤±è´¥: %w", err)
    }
    
    // åè®®æ•°æ®ç¼“å­˜30åˆ†é’Ÿ
    return w.cache.Set(ctx, key, jsonData, 30*time.Minute)
}

type TokenPrice struct {
    Address   string    `json:"address"`
    Symbol    string    `json:"symbol"`
    PriceUSD  float64   `json:"price_usd"`
    Timestamp time.Time `json:"timestamp"`
    Source    string    `json:"source"`
}
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### ç¼“å­˜æ€§èƒ½æµ‹è¯•

```go
package cache

import (
    "context"
    "fmt"
    "testing"
    "time"
)

func BenchmarkCacheOperations(b *testing.B) {
    ctx := context.Background()
    
    // æµ‹è¯•æ•°æ®
    testData := make([]byte, 1024) // 1KBæµ‹è¯•æ•°æ®
    for i := range testData {
        testData[i] = byte(i % 256)
    }
    
    // å†…å­˜ç¼“å­˜åŸºå‡†æµ‹è¯•
    b.Run("MemoryCache", func(b *testing.B) {
        memCache, _ := NewMemoryCache(&MemoryCacheConfig{
            MaxSize:     10000,
            TTL:         time.Hour,
            CleanupRate: time.Minute,
            MaxMemoryMB: 100,
        })
        
        b.ResetTimer()
        b.RunParallel(func(pb *testing.PB) {
            i := 0
            for pb.Next() {
                key := fmt.Sprintf("key_%d", i%1000)
                
                // å†™å…¥
                memCache.Set(ctx, key, testData, time.Hour)
                
                // è¯»å–
                memCache.Get(ctx, key)
                
                i++
            }
        })
    })
    
    // Redisç¼“å­˜åŸºå‡†æµ‹è¯•
    b.Run("RedisCache", func(b *testing.B) {
        redisCache, _ := NewRedisCache(&RedisConfig{
            Addr:     "localhost:6379",
            PoolSize: 100,
        }, nil)
        
        b.ResetTimer()
        b.RunParallel(func(pb *testing.PB) {
            i := 0
            for pb.Next() {
                key := fmt.Sprintf("key_%d", i%1000)
                
                // å†™å…¥
                redisCache.Set(ctx, key, testData, time.Hour)
                
                // è¯»å–
                redisCache.Get(ctx, key)
                
                i++
            }
        })
    })
}

func BenchmarkCacheHitRate(b *testing.B) {
    // æµ‹è¯•ä¸åŒç¼“å­˜å¤§å°ä¸‹çš„å‘½ä¸­ç‡
    sizes := []int{100, 1000, 10000}
    
    for _, size := range sizes {
        b.Run(fmt.Sprintf("Size_%d", size), func(b *testing.B) {
            cache, _ := NewMemoryCache(&MemoryCacheConfig{
                MaxSize:     size,
                TTL:         time.Hour,
                MaxMemoryMB: 1000,
            })
            
            ctx := context.Background()
            testData := []byte("test_data")
            
            b.ResetTimer()
            for i := 0; i < b.N; i++ {
                key := fmt.Sprintf("key_%d", i%size)
                cache.Set(ctx, key, testData, time.Hour)
                cache.Get(ctx, key)
            }
        })
    }
}
```

## ğŸ“ˆ æœ€ä½³å®è·µ

### 1. ç¼“å­˜é”®è®¾è®¡

```go
// æ ‡å‡†åŒ–çš„ç¼“å­˜é”®æ ¼å¼
type CacheKeyBuilder struct {
    namespace string
}

func NewCacheKeyBuilder(namespace string) *CacheKeyBuilder {
    return &CacheKeyBuilder{namespace: namespace}
}

func (ckb *CacheKeyBuilder) BlockKey(blockNumber uint64) string {
    return fmt.Sprintf("%s:block:%d", ckb.namespace, blockNumber)
}

func (ckb *CacheKeyBuilder) TransactionKey(txHash string) string {
    return fmt.Sprintf("%s:tx:%s", ckb.namespace, txHash)
}

func (ckb *CacheKeyBuilder) AddressBalanceKey(address string) string {
    return fmt.Sprintf("%s:balance:%s", ckb.namespace, address)
}

func (ckb *CacheKeyBuilder) TokenPriceKey(tokenAddr string) string {
    return fmt.Sprintf("%s:price:%s", ckb.namespace, tokenAddr)
}

func (ckb *CacheKeyBuilder) UserSessionKey(userID string) string {
    return fmt.Sprintf("%s:session:%s", ckb.namespace, userID)
}
```

### 2. ç¼“å­˜å¤±æ•ˆç­–ç•¥

```go
// æ™ºèƒ½å¤±æ•ˆç®¡ç†å™¨
type CacheInvalidator struct {
    cache       *SmartCacheManager
    logger      *zap.Logger
    patterns    map[string]time.Duration // å¤±æ•ˆæ¨¡å¼å’Œå‘¨æœŸ
}

func NewCacheInvalidator(cache *SmartCacheManager, logger *zap.Logger) *CacheInvalidator {
    ci := &CacheInvalidator{
        cache:    cache,
        logger:   logger,
        patterns: make(map[string]time.Duration),
    }
    
    // æ³¨å†Œé»˜è®¤å¤±æ•ˆæ¨¡å¼
    ci.patterns["price:*"] = time.Minute * 5     // ä»·æ ¼æ•°æ®5åˆ†é’Ÿå¤±æ•ˆ
    ci.patterns["balance:*"] = time.Minute * 10  // ä½™é¢æ•°æ®10åˆ†é’Ÿå¤±æ•ˆ
    ci.patterns["session:*"] = time.Hour * 1     // ä¼šè¯1å°æ—¶å¤±æ•ˆ
    
    return ci
}

// åŸºäºäº‹ä»¶çš„ç¼“å­˜å¤±æ•ˆ
func (ci *CacheInvalidator) InvalidateOnEvent(ctx context.Context, eventType string, data interface{}) error {
    switch eventType {
    case "new_block":
        // æ–°åŒºå—æ—¶å¤±æ•ˆç›¸å…³ç¼“å­˜
        return ci.invalidateBlockRelated(ctx, data)
    case "token_transfer":
        // ä»£å¸è½¬è´¦æ—¶å¤±æ•ˆä½™é¢ç¼“å­˜
        return ci.invalidateBalanceRelated(ctx, data)
    case "price_update":
        // ä»·æ ¼æ›´æ–°æ—¶å¤±æ•ˆä»·æ ¼ç¼“å­˜
        return ci.invalidatePriceRelated(ctx, data)
    }
    
    return nil
}

func (ci *CacheInvalidator) invalidateBlockRelated(ctx context.Context, data interface{}) error {
    // å¤±æ•ˆä¸æ–°åŒºå—ç›¸å…³çš„ç¼“å­˜
    // ä¾‹å¦‚ï¼šæœ€æ–°åŒºå—å·ã€å¾…ç¡®è®¤äº¤æ˜“ç­‰
    keys := []string{
        "latest_block",
        "pending_txs",
        "network_stats",
    }
    
    for _, key := range keys {
        if err := ci.cache.Delete(ctx, key); err != nil {
            ci.logger.Warn("å¤±æ•ˆç¼“å­˜å¤±è´¥", zap.String("key", key), zap.Error(err))
        }
    }
    
    return nil
}
```

### 3. ç¼“å­˜é¢„çƒ­

```go
// ç¼“å­˜é¢„çƒ­ç®¡ç†å™¨
type CacheWarmer struct {
    cache      *SmartCacheManager
    dataSource DataSourceInterface
    logger     *zap.Logger
}

func NewCacheWarmer(cache *SmartCacheManager, dataSource DataSourceInterface, logger *zap.Logger) *CacheWarmer {
    return &CacheWarmer{
        cache:      cache,
        dataSource: dataSource,
        logger:     logger,
    }
}

// ç³»ç»Ÿå¯åŠ¨æ—¶çš„é¢„çƒ­
func (cw *CacheWarmer) WarmupOnStartup(ctx context.Context) error {
    cw.logger.Info("å¼€å§‹ç³»ç»Ÿå¯åŠ¨é¢„çƒ­")
    
    // é¢„çƒ­æœ€æ–°åŒºå—æ•°æ®
    if err := cw.warmupLatestBlocks(ctx, 100); err != nil {
        return fmt.Errorf("é¢„çƒ­åŒºå—æ•°æ®å¤±è´¥: %w", err)
    }
    
    // é¢„çƒ­çƒ­é—¨ä»£å¸ä»·æ ¼
    if err := cw.warmupTokenPrices(ctx); err != nil {
        return fmt.Errorf("é¢„çƒ­ä»£å¸ä»·æ ¼å¤±è´¥: %w", err)
    }
    
    // é¢„çƒ­ç³»ç»Ÿç»Ÿè®¡æ•°æ®
    if err := cw.warmupSystemStats(ctx); err != nil {
        return fmt.Errorf("é¢„çƒ­ç³»ç»Ÿç»Ÿè®¡å¤±è´¥: %w", err)
    }
    
    cw.logger.Info("ç³»ç»Ÿå¯åŠ¨é¢„çƒ­å®Œæˆ")
    return nil
}

// å®šæœŸé¢„çƒ­
func (cw *CacheWarmer) ScheduledWarmup(ctx context.Context) {
    ticker := time.NewTicker(time.Hour)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            if err := cw.warmupTokenPrices(ctx); err != nil {
                cw.logger.Error("å®šæœŸé¢„çƒ­å¤±è´¥", zap.Error(err))
            }
        }
    }
}

func (cw *CacheWarmer) warmupLatestBlocks(ctx context.Context, count int) error {
    latestBlocks, err := cw.dataSource.GetLatestBlocks(ctx, count)
    if err != nil {
        return err
    }
    
    for _, block := range latestBlocks {
        key := fmt.Sprintf("block:%d", block.Number)
        data, _ := json.Marshal(block)
        cw.cache.Set(ctx, key, data, 24*time.Hour)
    }
    
    cw.logger.Info("é¢„çƒ­åŒºå—æ•°æ®å®Œæˆ", zap.Int("count", len(latestBlocks)))
    return nil
}

func (cw *CacheWarmer) warmupTokenPrices(ctx context.Context) error {
    // è·å–çƒ­é—¨ä»£å¸åˆ—è¡¨
    popularTokens, err := cw.dataSource.GetPopularTokens(ctx, 100)
    if err != nil {
        return err
    }
    
    // æ‰¹é‡è·å–ä»·æ ¼
    prices, err := cw.dataSource.GetTokenPrices(ctx, popularTokens)
    if err != nil {
        return err
    }
    
    // æ‰¹é‡å†™å…¥ç¼“å­˜
    for token, price := range prices {
        key := fmt.Sprintf("price:%s", token)
        data, _ := json.Marshal(price)
        cw.cache.Set(ctx, key, data, 5*time.Minute)
    }
    
    cw.logger.Info("é¢„çƒ­ä»£å¸ä»·æ ¼å®Œæˆ", zap.Int("count", len(prices)))
    return nil
}

func (cw *CacheWarmer) warmupSystemStats(ctx context.Context) error {
    stats, err := cw.dataSource.GetSystemStats(ctx)
    if err != nil {
        return err
    }
    
    key := "system_stats"
    data, _ := json.Marshal(stats)
    cw.cache.Set(ctx, key, data, 10*time.Minute)
    
    cw.logger.Info("é¢„çƒ­ç³»ç»Ÿç»Ÿè®¡å®Œæˆ")
    return nil
}

// æ•°æ®æºæ¥å£
type DataSourceInterface interface {
    GetLatestBlocks(ctx context.Context, count int) ([]*models.Block, error)
    GetPopularTokens(ctx context.Context, count int) ([]string, error)
    GetTokenPrices(ctx context.Context, tokens []string) (map[string]float64, error)
    GetSystemStats(ctx context.Context) (*SystemStats, error)
}

type SystemStats struct {
    TotalBlocks      uint64    `json:"total_blocks"`
    TotalTxs         uint64    `json:"total_txs"`
    ActiveAddresses  uint64    `json:"active_addresses"`
    NetworkHashrate  float64   `json:"network_hashrate"`
    AvgBlockTime     float64   `json:"avg_block_time"`
    LastUpdateTime   time.Time `json:"last_update_time"`
}
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

1. **ç¼“å­˜é›ªå´©**
   ```go
   // éšæœºTTLé¿å…åŒæ—¶å¤±æ•ˆ
   func randomTTL(baseTTL time.Duration) time.Duration {
       jitter := time.Duration(rand.Intn(300)) * time.Second  // 0-5åˆ†é’Ÿéšæœº
       return baseTTL + jitter
   }
   ```

2. **ç¼“å­˜å‡»ç©¿**
   ```go
   // ä½¿ç”¨åˆ†å¸ƒå¼é”
   func (cache *SmartCacheManager) GetWithLock(ctx context.Context, key string, loader func() ([]byte, error)) ([]byte, error) {
       // å°è¯•è·å–ç¼“å­˜
       if data, err := cache.Get(ctx, key); err == nil {
           return data, nil
       }
       
       // è·å–åˆ†å¸ƒå¼é”
       lockKey := "lock:" + key
       if locked, err := cache.l2Cache.(*RedisCache).Lock(ctx, lockKey, time.Minute); err != nil || !locked {
           // é”è·å–å¤±è´¥ï¼Œç­‰å¾…åé‡è¯•
           time.Sleep(100 * time.Millisecond)
           return cache.Get(ctx, key)
       }
       
       defer cache.l2Cache.(*RedisCache).Unlock(ctx, lockKey)
       
       // åŒé‡æ£€æŸ¥
       if data, err := cache.Get(ctx, key); err == nil {
           return data, nil
       }
       
       // åŠ è½½æ•°æ®
       data, err := loader()
       if err != nil {
           return nil, err
       }
       
       // å†™å…¥ç¼“å­˜
       cache.Set(ctx, key, data, 0)
       return data, nil
   }
   ```

3. **å†…å­˜æº¢å‡º**
   ```go
   // ç›‘æ§å†…å­˜ä½¿ç”¨
   func (mc *MemoryCache) checkMemoryUsage() {
       var m runtime.MemStats
       runtime.ReadMemStats(&m)
       
       if m.Alloc > uint64(mc.config.MaxMemoryMB)*1024*1024 {
           // è§¦å‘æ¸…ç†
           mc.bigCache.Reset()
           runtime.GC()
       }
   }
   ```

## ğŸ“Š ç›‘æ§é¢æ¿

### Grafana ç›‘æ§é…ç½®

```json
{
  "dashboard": {
    "title": "Web3 ç¼“å­˜ç›‘æ§",
    "panels": [
      {
        "title": "ç¼“å­˜å‘½ä¸­ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(cache_hits_total[5m]) / (rate(cache_hits_total[5m]) + rate(cache_misses_total[5m])) * 100"
          }
        ]
      },
      {
        "title": "ç¼“å­˜å»¶è¿Ÿ",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.95, cache_operation_duration_seconds)"
          }
        ]
      },
      {
        "title": "å†…å­˜ä½¿ç”¨",
        "type": "graph",
        "targets": [
          {
            "expr": "cache_memory_usage_bytes"
          }
        ]
      }
    ]
  }
}
```

---

**æœ€åæ›´æ–°**: 2025-01-13  
**ç»´æŠ¤å›¢é˜Ÿ**: Awesome Trade å¼€å‘å›¢é˜Ÿ
